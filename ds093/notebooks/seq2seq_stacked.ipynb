{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08af8a34-ea37-48ba-9e5b-cb56d10b01db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a625d9-7d99-4803-bf5c-74476f26dd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 07:52:25.789647: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "import urllib3\n",
    "import requests\n",
    "import gc\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from src.models.seq2seq import Encoder, Decoder, Seq2Seq\n",
    "from src.utils.session import reset_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e9434-6e43-4853-a3b1-2a620e898f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4514231c-e17c-4088-8d65-869b3e4745b0",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0525685e-8143-4b7d-a076-ed4a39f572b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../data\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# dataset path\n",
    "output_zip_path = os.path.join(base_dir, \"fra-eng.zip\")\n",
    "output_zip_dir = os.path.join(base_dir, \"fra-eng\")\n",
    "output_csv_path = os.path.join(base_dir, output_zip_dir, \"fra.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9c84f-2e4e-494a-bbfa-58e7330b2a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc717880-ef8b-4a7e-b7fa-bbae264a4acc",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e69a2d-dcf1-4222-a8cf-eb1642034547",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954f2d9d-28a2-416e-a3f6-b3cb302c84c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file downloaded to ../data/fra-eng.zip\n"
     ]
    }
   ],
   "source": [
    "def download_zip(url, output_path):\n",
    "    response = requests.get(url, headers=headers, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"ZIP file downloaded to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download. HTTP Response Code: {response.status_code}\")\n",
    "\n",
    "url = \"http://www.manythings.org/anki/fra-eng.zip\"\n",
    "download_zip(url, output_zip_path)\n",
    "\n",
    "# unzip\n",
    "with zipfile.ZipFile(output_zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(output_zip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e198aa-e772-496e-ab95-aa90c9003231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d2b61c2-64ba-4953-aaeb-294e08f4281a",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d20660-4926-47b7-8e24-75aa7b288b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(output_csv_path, header=None, names=[\"source\", \"target\", \"license\"], sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3313e066-4293-4ad6-ab0b-37a3d078e401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source      target                                            license\n",
       "0    Go.        Va !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1    Go.     Marche.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "2    Go.  En route !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "3    Go.     Bouge !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "4    Hi.     Salut !  CC-BY 2.0 (France) Attribution: tatoeba.org #5..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33010deb-b11d-49c6-9fa2-df7a7278331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop license column\n",
    "data.drop([\"license\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7968306-65e5-48df-a1f5-1516c1b02d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232736, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c560c5-df66-4422-a9f2-bb8326e749f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30329</th>\n",
       "      <td>Tom seems sincere.</td>\n",
       "      <td>Tom semble sincère.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>Tom wants to try it.</td>\n",
       "      <td>Tom veut l'essayer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30866</th>\n",
       "      <td>We're quite alone.</td>\n",
       "      <td>Nous sommes tout à fait seuls.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40447</th>\n",
       "      <td>Hey, listen to this.</td>\n",
       "      <td>Eh, écoutez ceci.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25580</th>\n",
       "      <td>Come talk with me.</td>\n",
       "      <td>Venez me parler.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>Stop arguing.</td>\n",
       "      <td>Arrête de te quereller !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26373</th>\n",
       "      <td>How are you doing?</td>\n",
       "      <td>Comment vas-tu ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9010</th>\n",
       "      <td>Pick a weapon.</td>\n",
       "      <td>Choisis une arme !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>Tom felt nothing.</td>\n",
       "      <td>Tom n'a rien ressenti.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Hug me.</td>\n",
       "      <td>Serre-moi dans tes bras !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     source                          target\n",
       "30329    Tom seems sincere.             Tom semble sincère.\n",
       "44957  Tom wants to try it.             Tom veut l'essayer.\n",
       "30866    We're quite alone.  Nous sommes tout à fait seuls.\n",
       "40447  Hey, listen to this.               Eh, écoutez ceci.\n",
       "25580    Come talk with me.                Venez me parler.\n",
       "6216          Stop arguing.        Arrête de te quereller !\n",
       "26373    How are you doing?                Comment vas-tu ?\n",
       "9010         Pick a weapon.              Choisis une arme !\n",
       "23445     Tom felt nothing.          Tom n'a rien ressenti.\n",
       "108                 Hug me.       Serre-moi dans tes bras !"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use first 60,000 rows to train the model\n",
    "data_sample = data.iloc[:60000].copy()\n",
    "\n",
    "np.random.seed(1234)\n",
    "data_sample.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be676b3-fd8a-4907-a17b-11d6b8a0d608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85b4f4a8-3fd2-4ef6-a825-0e2b6431fe29",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd72b96a-4fdb-4be5-b2e9-c46b48c63c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; Va ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; Marche. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; En route ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; Bouge ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>&lt;sos&gt; Salut ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                  target\n",
       "0    Go.        <sos> Va ! <eos>\n",
       "1    Go.     <sos> Marche. <eos>\n",
       "2    Go.  <sos> En route ! <eos>\n",
       "3    Go.     <sos> Bouge ! <eos>\n",
       "4    Hi.     <sos> Salut ! <eos>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add <sos>, <eos> symbol\n",
    "data_sample[\"target\"] = \"<sos> \" + data_sample[\"target\"] + \" <eos>\"\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e57acc5b-fdf8-4d1d-bcc3-6a4a599bcd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Source Vocab: 80\n",
      "Length of Target Vocab: 102\n"
     ]
    }
   ],
   "source": [
    "# create source/target vocab\n",
    "source_vocab = set()\n",
    "target_vocab = set()\n",
    "for _, row in data_sample.iterrows():\n",
    "    source_vocab.update(list(row.source))\n",
    "    target_vocab.update([\"<sos>\"] + list(row.target.lstrip(\"<sos>\").rstrip(\"<eos>\")) + [\"<eos>\"])\n",
    "\n",
    "source_vocab_size = len(source_vocab) + 1\n",
    "target_vocab_size = len(target_vocab) + 1\n",
    "print(f\"Length of Source Vocab: {source_vocab_size}\")\n",
    "print(f\"Length of Target Vocab: {target_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab798844-2fbf-45e3-96aa-5b7c8240688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char to idx\n",
    "source_to_index = {w: i+1 for i, w in enumerate(source_vocab)}\n",
    "target_to_index = {w: i+1 for i, w in enumerate(target_vocab)}\n",
    "\n",
    "index_to_source = {v: k for k, v in source_to_index.items()}\n",
    "index_to_target = {v: k for k, v in target_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab9b6143-b1ae-4b68-ad79-8aac75220268",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_idx = {\n",
    "    \"encoder_input\": [],\n",
    "    \"decoder_input\": [],\n",
    "    \"decoder_target\": []\n",
    "}\n",
    "for _, row in data_sample.iterrows():\n",
    "    inputs_idx[\"encoder_input\"].append([source_to_index[c] for c in row.source])\n",
    "\n",
    "    target_encoded = [target_to_index[c] for c in row.target.lstrip(\"<sos>\").rstrip(\"<eos>\")]\n",
    "    inputs_idx[\"decoder_input\"].append([target_to_index[\"<sos>\"]] + target_encoded + [target_to_index[\"<eos>\"]])\n",
    "    inputs_idx[\"decoder_target\"].append(target_encoded + [target_to_index[\"<eos>\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4cc86b3-a519-412b-b34f-3eb4b49c3a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[42, 67, 75], [42, 67, 75], [42, 67, 75], [42, 67, 75], [4, 12, 75]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_idx[\"encoder_input\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e1bded2-5517-41e4-b35d-8b952641983f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[68, 67, 12, 39, 67, 42, 67, 97],\n",
       " [68, 67, 95, 39, 16, 2, 79, 83, 96, 67, 97],\n",
       " [68, 67, 75, 41, 67, 16, 87, 17, 101, 83, 67, 42, 67, 97],\n",
       " [68, 67, 3, 87, 17, 5, 83, 67, 42, 67, 97],\n",
       " [68, 67, 89, 39, 92, 17, 101, 67, 42, 67, 97]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_idx[\"decoder_input\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64c0bd31-12bb-4d8b-97e6-0988f17450b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[67, 12, 39, 67, 42, 67, 97],\n",
       " [67, 95, 39, 16, 2, 79, 83, 96, 67, 97],\n",
       " [67, 75, 41, 67, 16, 87, 17, 101, 83, 67, 42, 67, 97],\n",
       " [67, 3, 87, 17, 5, 83, 67, 42, 67, 97],\n",
       " [67, 89, 39, 92, 17, 101, 67, 42, 67, 97]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_idx[\"decoder_target\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1967e69-fddb-4841-9835-df85518fdd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max source length: 22\n",
      "max target length: 76\n"
     ]
    }
   ],
   "source": [
    "max_source_len = max(map(len, inputs_idx[\"encoder_input\"]))\n",
    "max_target_len = max(map(len, inputs_idx[\"decoder_input\"]))\n",
    "\n",
    "print(f\"max source length: {max_source_len}\")\n",
    "print(f\"max target length: {max_target_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "329a401c-ff00-443c-9449-19ffe0e2a9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input shape: (60000, 22)\n",
      "decoder input shape: (60000, 76)\n",
      "decoder target shape: (60000, 75)\n"
     ]
    }
   ],
   "source": [
    "inputs_pad = {}\n",
    "\n",
    "inputs_pad[\"encoder_input\"] = pad_sequences(inputs_idx[\"encoder_input\"], maxlen=max_source_len, padding=\"post\")\n",
    "inputs_pad[\"decoder_input\"] = pad_sequences(inputs_idx[\"decoder_input\"], maxlen=max_target_len, padding=\"post\")\n",
    "inputs_pad[\"decoder_target\"] = pad_sequences(inputs_idx[\"decoder_target\"], maxlen=max_target_len-1, padding=\"post\")\n",
    "\n",
    "print(f\"encoder input shape: {inputs_pad['encoder_input'].shape}\")\n",
    "print(f\"decoder input shape: {inputs_pad['decoder_input'].shape}\")\n",
    "print(f\"decoder target shape: {inputs_pad['decoder_target'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b719dd-a0da-49df-ad11-20a6d537fc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input shape: (60000, 22, 80)\n",
      "decoder input shape: (60000, 76, 102)\n",
      "decoder target shape: (60000, 75, 102)\n"
     ]
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "inputs[\"encoder_input\"] = to_categorical(inputs_pad[\"encoder_input\"])\n",
    "inputs[\"decoder_input\"] = to_categorical(inputs_pad[\"decoder_input\"])\n",
    "inputs[\"decoder_target\"] = to_categorical(inputs_pad[\"decoder_target\"])\n",
    "\n",
    "# note that len(source_vocab) = 79, len(target_vocab) = 101\n",
    "print(f\"encoder input shape: {inputs['encoder_input'].shape}\")\n",
    "print(f\"decoder input shape: {inputs['decoder_input'].shape}\")\n",
    "print(f\"decoder target shape: {inputs['decoder_target'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcfe9d0e-1b49-4c3f-bb03-3f1a7a6433b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ' '.join([index_to_source[v] for v in tf.argmax(inputs[\"encoder_input\"][0], axis=1).numpy() if v != 0])\n",
    "# ' '.join([index_to_target[v] for v in tf.argmax(inputs[\"decoder_input\"][0], axis=1).numpy() if v != 0])\n",
    "# ' '.join([index_to_target[v] for v in tf.argmax(inputs[\"decoder_target\"][0], axis=1).numpy() if v != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249dde4c-11e2-4e86-a3d4-ab182f132f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc211f9-4f04-4dc1-b34a-8a47a2a8085c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d2c739f-50f7-46e5-a9cc-19c708811a86",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50e6c825-f2fb-4a82-ab67-265dfeceb98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b546c13a-3f7c-4e2c-a430-c37abb275b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 07:52:37.583982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 07:52:37.586436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 07:52:37.586576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 07:52:37.587009: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-21 07:52:37.587353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 07:52:37.587511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 07:52:37.587649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 07:52:37.940751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 07:52:37.940881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 07:52:37.940973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 07:52:37.941057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6660 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(\n",
    "    input_dim=source_vocab_size,\n",
    "    output_dim=target_vocab_size,\n",
    "    hidden_dim=256,\n",
    "    num_layers=3,\n",
    "    max_length=max_target_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5da0d9de-5051-48f1-87a2-f50c50b945e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.build(optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f71ebe64-b185-4180-b205-2e899dea75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1, inp2 = inputs[\"encoder_input\"], inputs[\"decoder_input\"]\n",
    "X = [inp1, inp2]\n",
    "y = np.argmax(inputs[\"decoder_target\"], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "116e1d5c-f62f-48f4-ac53-b907a4bbb132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 07:56:03.267687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-12-21 07:56:07.948887: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f5e7cef03b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-21 07:56:07.948912: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2024-12-21 07:56:07.986475: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-21 07:56:08.352183: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 264s 871ms/step - loss: 0.9249 - val_loss: 0.9534\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 36s 385ms/step - loss: 0.7415 - val_loss: 0.8582\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 37s 397ms/step - loss: 0.6729 - val_loss: 0.7893\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 34s 366ms/step - loss: 0.6332 - val_loss: 0.7562\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 36s 379ms/step - loss: 0.6042 - val_loss: 0.7259\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 35s 368ms/step - loss: 0.5814 - val_loss: 0.6992\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 36s 379ms/step - loss: 0.5640 - val_loss: 0.6832\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 37s 388ms/step - loss: 0.5488 - val_loss: 0.6718\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 37s 388ms/step - loss: 0.5368 - val_loss: 0.6543\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 35s 371ms/step - loss: 0.5271 - val_loss: 0.6456\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 34s 366ms/step - loss: 0.5187 - val_loss: 0.6359\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 36s 381ms/step - loss: 0.5111 - val_loss: 0.6309\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 34s 362ms/step - loss: 0.5048 - val_loss: 0.6214\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 38s 401ms/step - loss: 0.4998 - val_loss: 0.6222\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 35s 368ms/step - loss: 0.4946 - val_loss: 0.6172\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 34s 368ms/step - loss: 0.4892 - val_loss: 0.6157\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 36s 383ms/step - loss: 0.4859 - val_loss: 0.6093\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 35s 369ms/step - loss: 0.4819 - val_loss: 0.6070\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 36s 387ms/step - loss: 0.4787 - val_loss: 0.6078\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 37s 388ms/step - loss: 0.4767 - val_loss: 0.6009\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 36s 387ms/step - loss: 0.4733 - val_loss: 0.6028\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 36s 377ms/step - loss: 0.4725 - val_loss: 0.6033\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 35s 371ms/step - loss: 0.4686 - val_loss: 0.5965\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 36s 384ms/step - loss: 0.4657 - val_loss: 0.5958\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 35s 371ms/step - loss: 0.4643 - val_loss: 0.5912\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 36s 381ms/step - loss: 0.4629 - val_loss: 0.5928\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 37s 396ms/step - loss: 0.4596 - val_loss: 0.5947\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 37s 389ms/step - loss: 0.4572 - val_loss: 0.5923\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 36s 377ms/step - loss: 0.4558 - val_loss: 0.5859\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 36s 386ms/step - loss: 0.4558 - val_loss: 0.5904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f38403d00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: add early stopping callback\n",
    "seq2seq.fit(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    batch_size=512,\n",
    "    epochs=30,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12db1a5b-5add-499d-9697-bead08ba6b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Source: We all suffered.\n",
      "Predict: Nous aoons de la maite.\n",
      "Answer: Nous avons tous souffert.\n",
      "==================================================\n",
      "Source: Why do you think so?\n",
      "Predict: Pourquoi ne peux-tu pas ?\n",
      "Answer: Pourquoi pensez-vous ça ?\n",
      "==================================================\n",
      "Source: Just take one.\n",
      "Predict: Attendsz de lois !\n",
      "Answer: Prenez-en seulement un.\n",
      "==================================================\n",
      "Source: Tom misled Mary.\n",
      "Predict: Tom a me les chausss.\n",
      "Answer: Tom trompait Marie.\n",
      "==================================================\n",
      "Source: I'm busy, too.\n",
      "Predict: Je suis très contraré.\n",
      "Answer: Je suis également affairé.\n",
      "==================================================\n",
      "Source: Here's your milk.\n",
      "Predict: Montrezmoi une cha\n",
      "Answer: Voici ton lait.\n",
      "==================================================\n",
      "Source: This book is smaller.\n",
      "Predict: Ce livre est malhe.\n",
      "Answer: Ce livre est plus petit.\n",
      "==================================================\n",
      "Source: Nobody likes you.\n",
      "Predict: Personne ne peut parer\n",
      "Answer: Personne ne t'aime.\n",
      "==================================================\n",
      "Source: I'm glad to hear that.\n",
      "Predict: Je suis très contraré.\n",
      "Answer: C'est bon à entendre.\n",
      "==================================================\n",
      "Source: Where is the exit?\n",
      "Predict: Où est lon chambre ?\n",
      "Answer: Où est la sortie ?\n"
     ]
    }
   ],
   "source": [
    "examples = data_sample.sample(10)\n",
    "for rn, row in examples.iterrows():\n",
    "    pred = seq2seq.predict_sequence(\n",
    "        inputs[\"encoder_input\"][rn],\n",
    "        sos_token_index=target_to_index[\"<sos>\"],\n",
    "        index_to_target=index_to_target,\n",
    "    )\n",
    "    print(\"=====\"*10)\n",
    "    print(f\"Source: {row.source}\")\n",
    "    print(f\"Predict: {pred.lstrip(' ').rstrip(' <eos>')}\")\n",
    "    print(f\"Answer: {row.target.lstrip('<sos> ').rstrip(' <eos>')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eded44-6bca-49b4-acaa-fb27247d0423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea4ba2-2e0d-4c93-bd6d-21ea576979cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326d8bc-195b-4c14-bffd-6cb5b7ce68f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13261a1-489b-404b-a637-8750dd3c04b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8272bb23-b83f-4153-b247-b441ce6971c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs = 32\n",
    "# outs = model([inp1[:bs], inp2[:bs]], training=True)\n",
    "# tars = y[:bs]\n",
    "\n",
    "# tars.shape\n",
    "# outs.shape\n",
    "\n",
    "# seq2seq.loss_function(tars, outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "648d19a0-d3f2-4d6b-8296-4134f8842eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs = 32\n",
    "# inp1, inp2 = inputs[\"encoder_input\"][:bs], inputs[\"decoder_input\"][:bs]\n",
    "# X = [inp1, inp2]\n",
    "# y = np.argmax(inputs[\"decoder_target\"], axis=-1)\n",
    "# enc_states = seq2seq.encoder.initialize_hidden_state(bs)\n",
    "\n",
    "# enc_out, *enc_states = seq2seq.encoder(inp1, enc_states)\n",
    "# dec_out, *dec_states = seq2seq.decoder(inp2, enc_states)\n",
    "\n",
    "# # encoder initial states\n",
    "# batch_size = tf.shape(inp1)[0]\n",
    "# enc_states = seq2seq.encoder.initialize_hidden_state(bs)\n",
    "\n",
    "# # encoder outputs & states\n",
    "# _, *enc_states = seq2seq.encoder(inp1, states=enc_states)\n",
    "# dec_states = enc_states\n",
    "\n",
    "# dec_outs = []\n",
    "# dec_inp = tf.expand_dims(inp2[:, 0], axis=1)\n",
    "# for t in range(1, seq2seq.max_length):\n",
    "#     out, *dec_states = seq2seq.decoder(dec_inp, dec_states)\n",
    "#     dec_outs.append(out)\n",
    "#     dec_inp = tf.expand_dims(inp2[:, t], axis=1)\n",
    "\n",
    "# # tf.concat(dec_outs, axis=1).shape\n",
    "# dec_outs = seq2seq.call(inp1, inp2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003c487-cb58-4d39-a613-68d28f9cc406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e728c7-9588-461d-9102-b39e67e76e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
