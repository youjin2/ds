{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815cdacc-9951-4d15-a093-e26c679dda78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 13:38:29.657907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import urllib3\n",
    "import requests\n",
    "import gc\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa641f-952a-45c6-a0b8-6fa59267d050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04776698-85fe-4691-bcf9-e8aab25bea02",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670f1f9e-39f6-4306-9850-4f96c8d34f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../data\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# dataset path\n",
    "output_zip_path = os.path.join(base_dir, \"fra-eng.zip\")\n",
    "output_zip_dir = os.path.join(base_dir, \"fra-eng\")\n",
    "output_csv_path = os.path.join(base_dir, output_zip_dir, \"fra.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228f631-59a9-428f-aaa5-13fe01941f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6afa8e5e-d685-4473-a972-8056827eff99",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e08c4d-3699-4ff9-89c8-8b5be1aa9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25287a95-570c-40a9-aa4d-d345b975e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file downloaded to ../data/fra-eng.zip\n"
     ]
    }
   ],
   "source": [
    "def download_zip(url, output_path):\n",
    "    response = requests.get(url, headers=headers, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"ZIP file downloaded to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download. HTTP Response Code: {response.status_code}\")\n",
    "\n",
    "url = \"http://www.manythings.org/anki/fra-eng.zip\"\n",
    "download_zip(url, output_zip_path)\n",
    "\n",
    "# unzip\n",
    "with zipfile.ZipFile(output_zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(output_zip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a1ef27-22ef-4740-8bf5-5783c4f0d40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77a762e2-30df-45c8-bd22-25594734573a",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4de72c-39f4-4183-ad57-057d7a0d63d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(output_csv_path, header=None, names=[\"source\", \"target\", \"license\"], sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "801d630d-44f4-497c-afe7-c955d207f424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source      target                                            license\n",
       "0    Go.        Va !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1    Go.     Marche.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "2    Go.  En route !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "3    Go.     Bouge !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "4    Hi.     Salut !  CC-BY 2.0 (France) Attribution: tatoeba.org #5..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8db5d96-24a1-4132-bf3b-566a0e6996ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop license column\n",
    "data.drop([\"license\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c4656b-afc7-4267-97fd-7eff444301ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232736, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faccf680-8037-4d30-bd42-6b6d44bb3f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30329</th>\n",
       "      <td>Tom seems sincere.</td>\n",
       "      <td>Tom semble sincère.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>Tom wants to try it.</td>\n",
       "      <td>Tom veut l'essayer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30866</th>\n",
       "      <td>We're quite alone.</td>\n",
       "      <td>Nous sommes tout à fait seuls.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40447</th>\n",
       "      <td>Hey, listen to this.</td>\n",
       "      <td>Eh, écoutez ceci.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25580</th>\n",
       "      <td>Come talk with me.</td>\n",
       "      <td>Venez me parler.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>Stop arguing.</td>\n",
       "      <td>Arrête de te quereller !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26373</th>\n",
       "      <td>How are you doing?</td>\n",
       "      <td>Comment vas-tu ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9010</th>\n",
       "      <td>Pick a weapon.</td>\n",
       "      <td>Choisis une arme !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>Tom felt nothing.</td>\n",
       "      <td>Tom n'a rien ressenti.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Hug me.</td>\n",
       "      <td>Serre-moi dans tes bras !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     source                          target\n",
       "30329    Tom seems sincere.             Tom semble sincère.\n",
       "44957  Tom wants to try it.             Tom veut l'essayer.\n",
       "30866    We're quite alone.  Nous sommes tout à fait seuls.\n",
       "40447  Hey, listen to this.               Eh, écoutez ceci.\n",
       "25580    Come talk with me.                Venez me parler.\n",
       "6216          Stop arguing.        Arrête de te quereller !\n",
       "26373    How are you doing?                Comment vas-tu ?\n",
       "9010         Pick a weapon.              Choisis une arme !\n",
       "23445     Tom felt nothing.          Tom n'a rien ressenti.\n",
       "108                 Hug me.       Serre-moi dans tes bras !"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use first 60,000 rows to train the model\n",
    "data_sample = data.iloc[:60000].copy()\n",
    "\n",
    "np.random.seed(1234)\n",
    "data_sample.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29799f70-6805-414a-89a9-d2474b2b2cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "684d1e88-af2f-45cb-81d2-9cee1a5c14c6",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23db231f-fbe5-4283-ab53-64eca4369824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; Va ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; Marche. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; En route ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; Bouge ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>&lt;sos&gt; Salut ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                  target\n",
       "0    Go.        <sos> Va ! <eos>\n",
       "1    Go.     <sos> Marche. <eos>\n",
       "2    Go.  <sos> En route ! <eos>\n",
       "3    Go.     <sos> Bouge ! <eos>\n",
       "4    Hi.     <sos> Salut ! <eos>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add <sos>, <eos> symbol\n",
    "data_sample[\"target\"] = \"<sos> \" + data_sample[\"target\"] + \" <eos>\"\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "730732b2-d04d-43fe-aa5a-481d8ecd7b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Source Vocab: 80\n",
      "Length of Target Vocab: 102\n"
     ]
    }
   ],
   "source": [
    "# create source/target vocab\n",
    "source_vocab = set()\n",
    "target_vocab = set()\n",
    "for _, row in data_sample.iterrows():\n",
    "    source_vocab.update(list(row.source))\n",
    "    target_vocab.update([\"<sos>\"] + list(row.target.lstrip(\"<sos>\").rstrip(\"<eos>\")) + [\"<eos>\"])\n",
    "\n",
    "source_vocab_size = len(source_vocab) + 1\n",
    "target_vocab_size = len(target_vocab) + 1\n",
    "print(f\"Length of Source Vocab: {source_vocab_size}\")\n",
    "print(f\"Length of Target Vocab: {target_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65221ca4-f1d9-4622-b606-0f4f6e450640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char to idx\n",
    "source_to_index = {w: i+1 for i, w in enumerate(source_vocab)}\n",
    "target_to_index = {w: i+1 for i, w in enumerate(target_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be46687a-cc2c-4f16-a25c-f1e4d8c144a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = []\n",
    "decoder_inputs = []\n",
    "decoder_targets = []\n",
    "for _, row in data_sample.iterrows():\n",
    "    encoder_inputs.append([source_to_index[c] for c in row.source])\n",
    "\n",
    "    target_encoded = [target_to_index[c] for c in row.target.lstrip(\"<sos>\").rstrip(\"<eos>\")]\n",
    "    decoder_inputs.append([target_to_index[\"<sos>\"]] + target_encoded + [target_to_index[\"<eos>\"]])\n",
    "    decoder_targets.append(target_encoded + [target_to_index[\"<eos>\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e12279-6ef7-4b2f-adb1-bd8f1729596f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[59, 32, 8], [59, 32, 8], [59, 32, 8], [59, 32, 8], [35, 76, 8]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd739794-ca01-48ab-9a64-255a8c549d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[58, 37, 83, 41, 37, 36, 37, 89],\n",
       " [58, 37, 26, 41, 25, 40, 12, 48, 11, 37, 89],\n",
       " [58, 37, 99, 51, 37, 25, 39, 6, 93, 48, 37, 36, 37, 89],\n",
       " [58, 37, 75, 39, 6, 82, 48, 37, 36, 37, 89],\n",
       " [58, 37, 62, 41, 49, 6, 93, 37, 36, 37, 89]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce8903b3-1b24-466f-9708-d077e98a8e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37, 83, 41, 37, 36, 37, 89],\n",
       " [37, 26, 41, 25, 40, 12, 48, 11, 37, 89],\n",
       " [37, 99, 51, 37, 25, 39, 6, 93, 48, 37, 36, 37, 89],\n",
       " [37, 75, 39, 6, 82, 48, 37, 36, 37, 89],\n",
       " [37, 62, 41, 49, 6, 93, 37, 36, 37, 89]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d5afc4c-c4b7-4b57-bff9-b4fd04df98e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max source length: 22\n",
      "max target length: 76\n"
     ]
    }
   ],
   "source": [
    "max_source_len = max(map(len, encoder_inputs))\n",
    "max_target_len = max(map(len, decoder_inputs))\n",
    "\n",
    "print(f\"max source length: {max_source_len}\")\n",
    "print(f\"max target length: {max_target_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a78063e2-57ec-48c5-a889-5a2c3b7c9302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input shape: (60000, 22)\n",
      "decoder input shape: (60000, 76)\n",
      "decoder target shape: (60000, 76)\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = pad_sequences(encoder_inputs, maxlen=max_source_len, padding=\"post\")\n",
    "decoder_inputs = pad_sequences(decoder_inputs, maxlen=max_target_len, padding=\"post\")\n",
    "decoder_targets = pad_sequences(decoder_targets, maxlen=max_target_len, padding=\"post\")\n",
    "\n",
    "print(f\"encoder input shape: {encoder_inputs.shape}\")\n",
    "print(f\"decoder input shape: {decoder_inputs.shape}\")\n",
    "print(f\"decoder target shape: {decoder_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8194a64-0722-4f0d-8d46-dbc1fb1c49fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input shape: (60000, 22, 80)\n",
      "decoder input shape: (60000, 76, 102)\n",
      "decoder target shape: (60000, 76, 102)\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = to_categorical(encoder_inputs)\n",
    "decoder_inputs = to_categorical(decoder_inputs)\n",
    "decoder_targets = to_categorical(decoder_targets)\n",
    "\n",
    "# note that len(source_vocab) = 79, len(target_vocab) = 101\n",
    "print(f\"encoder input shape: {encoder_inputs.shape}\")\n",
    "print(f\"decoder input shape: {decoder_inputs.shape}\")\n",
    "print(f\"decoder target shape: {decoder_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424d836-fec9-4e0b-b716-f62bade269a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1acfb28-0f28-46a6-997a-a46a338d81c7",
   "metadata": {},
   "source": [
    "## Build Vanilla seq2seq (without Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dd13b53-1492-4b9f-94d0-5ef64b752c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaSeq2Seq:\n",
    "    def __init__(\n",
    "        self,        \n",
    "        souce_vocab_size: int,\n",
    "        target_vocab_size: int,\n",
    "        num_hidden: int = 256,\n",
    "        initial_learning_rate: float = 1e-3\n",
    "    ) -> None:\n",
    "        self._num_hidden = num_hidden\n",
    "        self._source_vocab_size = souce_vocab_size\n",
    "        self._target_vocab_size = target_vocab_size\n",
    "        self._initial_learning_rate = initial_learning_rate\n",
    "    \n",
    "    def build(self) -> None:\n",
    "        encoder_inputs = Input(shape=(None, self._source_vocab_size))\n",
    "        encoder_lstm = LSTM(units=self._num_hidden, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "        decoder_inputs = Input(shape=(None, self._target_vocab_size))\n",
    "        decoder_lstm = LSTM(units=self._num_hidden, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "        decoder_dense = Dense(self._target_vocab_size, activation=\"softmax\")\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "        model.compile(optimizer=Adam(self._initial_learning_rate), loss=\"categorical_crossentropy\")\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "        # used to predict the sequence\n",
    "        self.encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
    "        decoder_state_input_h = Input(shape=(self._num_hidden,))\n",
    "        decoder_state_input_c = Input(shape=(self._num_hidden,))\n",
    "        decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        self.decoder_model = Model(\n",
    "            inputs=[decoder_inputs] + decoder_state_inputs,\n",
    "            outputs=[decoder_outputs] + decoder_states,\n",
    "        )\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: List[np.ndarray],\n",
    "        y: np.ndarray,\n",
    "        batch_size: int = 128,\n",
    "        epochs: int = 50,\n",
    "        validation_split: float = 0.2,\n",
    "    ) -> None:\n",
    "        self.model.fit(\n",
    "            x=X,\n",
    "            y=y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=validation_split,\n",
    "        )\n",
    "\n",
    "    def predict_sequence(\n",
    "        self,\n",
    "        input_sequence: np.ndarray,\n",
    "        index_to_target: Dict[int, str],\n",
    "        sos_token_index: int,\n",
    "    ) -> str:\n",
    "        if len(input_sequence.shape) != 2:\n",
    "            raise ValueError(\"input sequence must be 2-dimensional\")\n",
    "\n",
    "        inputs = np.expand_dims(input_sequence, axis=0)\n",
    "        states = self.encoder_model.predict(inputs, verbose=False)\n",
    "        \n",
    "        target_sequence = np.zeros((1, 1, self._target_vocab_size))\n",
    "        target_sequence[0, 0, sos_token_index] = 1\n",
    "        stop_condition = False\n",
    "        decoded_sentence = \"\"\n",
    "        while not stop_condition:\n",
    "            out, h, c = self.decoder_model.predict([target_sequence] + states, verbose=False)\n",
    "            token_idx = np.argmax(out[0, -1, :])\n",
    "            char = index_to_target.get(token_idx, \" \")\n",
    "            decoded_sentence += char\n",
    "        \n",
    "            if char == \"<eos>\" or len(decoded_sentence) > max_target_len:\n",
    "                stop_condition = True\n",
    "        \n",
    "            target_sequence = np.zeros((1, 1, self._target_vocab_size))\n",
    "            target_sequence[0, 0, token_idx] = 1.\n",
    "            states = [h, c]\n",
    "        return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baba303d-f7de-4259-a293-23ea39c0cae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to prevent memory leak\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13f4bab6-3e65-45f0-ab3d-13e725e519d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 13:38:40.749699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-06 13:38:40.757249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-06 13:38:40.757742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-06 13:38:40.759907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-06 13:38:40.761194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-06 13:38:40.761711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-06 13:38:40.762147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-06 13:38:41.113048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-06 13:38:41.113221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-06 13:38:41.113313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-06 13:38:41.113395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6660 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "seq2seq = VanillaSeq2Seq(\n",
    "    souce_vocab_size=source_vocab_size,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    initial_learning_rate=1e-2,\n",
    ")\n",
    "seq2seq.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a591462f-cfe6-4cb6-a85f-622e0f6af10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 13:38:41.812283: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1488384000 exceeds 10% of free system memory.\n",
      "2024-12-06 13:38:42.424903: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1488384000 exceeds 10% of free system memory.\n",
      "2024-12-06 13:38:43.156510: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1488384000 exceeds 10% of free system memory.\n",
      "2024-12-06 13:38:43.596256: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1488384000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 13:38:46.212838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-12-06 13:38:46.586163: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1eeaf700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-06 13:38:46.586190: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2024-12-06 13:38:46.589185: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-06 13:38:46.683162: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 8s 52ms/step - loss: 1.1250 - val_loss: 0.8251\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.6113 - val_loss: 0.6914\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 4s 39ms/step - loss: 0.5267 - val_loss: 0.6352\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.4879 - val_loss: 0.5906\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.4501 - val_loss: 0.5476\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.4176 - val_loss: 0.5161\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.3919 - val_loss: 0.4895\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 4s 39ms/step - loss: 0.3710 - val_loss: 0.4670\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.3536 - val_loss: 0.4498\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.3386 - val_loss: 0.4336\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.3304 - val_loss: 0.4204\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.3169 - val_loss: 0.4095\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.3040 - val_loss: 0.3966\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.2925 - val_loss: 0.3871\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.2839 - val_loss: 0.3781\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.2753 - val_loss: 0.3708\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.2677 - val_loss: 0.3653\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.2606 - val_loss: 0.3596\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.2541 - val_loss: 0.3556\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.2484 - val_loss: 0.3510\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 4s 39ms/step - loss: 0.2432 - val_loss: 0.3488\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.2379 - val_loss: 0.3461\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.2335 - val_loss: 0.3428\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.2282 - val_loss: 0.3387\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.2236 - val_loss: 0.3369\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 4s 39ms/step - loss: 0.2195 - val_loss: 0.3353\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.2152 - val_loss: 0.3348\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.2113 - val_loss: 0.3335\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.2077 - val_loss: 0.3320\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.2038 - val_loss: 0.3319\n"
     ]
    }
   ],
   "source": [
    "seq2seq.fit(\n",
    "    X=[encoder_inputs, decoder_inputs],\n",
    "    y=decoder_targets,\n",
    "    batch_size=512,\n",
    "    epochs=30,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa3b87a7-eac1-46c1-9e6a-5bc5057e4f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 80)]   0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 102)]  0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        345088      ['input_1[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  367616      ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 102)    26214       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 738,918\n",
      "Trainable params: 738,918\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38ad8343-81b4-41e0-b9b7-a68528a9e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_target = {v: k for k, v in target_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffa58fb8-4388-4102-bf64-513fca9bf98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Source: I can't fake it.\n",
      "Predict: Je ne peux pas le faire.\n",
      "Answer: Je ne peux pas le simuler.\n",
      "==================================================\n",
      "Source: I'll beat you up!\n",
      "Predict: Je suis en train de parler.\n",
      "Answer: Je vais te cogner !\n",
      "==================================================\n",
      "Source: Tom got embarrassed.\n",
      "Predict: Tom a été prévenue.\n",
      "Answer: Tom a été embarrassé.\n",
      "==================================================\n",
      "Source: Tom's cheerful.\n",
      "Predict: Tom est plein de travail.\n",
      "Answer: Tom est de bonne humeur.\n",
      "==================================================\n",
      "Source: Either is acceptable.\n",
      "Predict: Fais ce que j'ai tort.\n",
      "Answer: N'importe laquelle est acceptable.\n",
      "==================================================\n",
      "Source: We were eating pizza.\n",
      "Predict: Nous avons toutes des mousins.\n",
      "Answer: Nous mangions de la pizza.\n",
      "==================================================\n",
      "Source: I have to find that.\n",
      "Predict: Je dois te laisser.\n",
      "Answer: Je dois trouver ça.\n",
      "==================================================\n",
      "Source: Look closely.\n",
      "Predict: Regarde ce que tu veux.\n",
      "Answer: Regarde attentivement.\n",
      "==================================================\n",
      "Source: They saved us.\n",
      "Predict: Elles ont tous deux chiens.\n",
      "Answer: Elles nous ont sauvés.\n",
      "==================================================\n",
      "Source: I know her very well.\n",
      "Predict: Je sais que tu es sorti.\n",
      "Answer: Je la connais très bien.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "examples = data_sample.sample(10)\n",
    "for rn, row in examples.iterrows():\n",
    "    pred = seq2seq.predict_sequence(\n",
    "        encoder_inputs[rn],\n",
    "        sos_token_index=target_to_index[\"<sos>\"],\n",
    "        index_to_target=index_to_target,\n",
    "    )\n",
    "    print(\"=====\"*10)\n",
    "    print(f\"Source: {row.source}\")\n",
    "    print(f\"Predict: {pred.lstrip(' ').rstrip(' <eos>')}\")\n",
    "    print(f\"Answer: {row.target.lstrip('<sos> ').rstrip(' <eos>')}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8689458c-366a-41d1-82e9-9742dd02b19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853cf53-ae49-419f-a89a-aff2821190a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94964c1-df32-46f3-8630-46ba38fb2e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4adf875-8a93-45d0-977f-0f29edb06254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
