{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68352fe6-96fe-40fd-9c2e-92e93e427993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "from typing import Dict, List, Tuple, Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db92d8-4f02-4613-bad9-740da72e4866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "791ec5dd-129f-486b-a8b9-5b2a76495187",
   "metadata": {},
   "source": [
    "## 1. BPE (Byte Pair Encoding)\n",
    "\n",
    "BPE is a data compression algorithm proposed in 1994.  \n",
    "Basically, it works by finding a pair of consecutive words most frequently appeared, and merged it into one letter.\n",
    "\n",
    "- e.g. `aaabdaaabac`\n",
    "    - `Z=aa` $\\rightarrow$   `ZabdZabac`\n",
    "    - `Z=aa, Y=ab` $\\rightarrow$  `ZYdZYac`\n",
    "    - `Z=aa, Y=ab, X=ZY` $\\rightarrow$  `XdXac`\n",
    "\n",
    "In natural language preprocessing, BPE is a subword segmentation algorithm, which means it splits exsiting word.\n",
    "- e.g. frequency of each word in train vocaburay\n",
    "    ```python\n",
    "    # dictionary (frequency of each word in train vocaburary)\n",
    "    low : 5, lower : 2, newest : 6, widest : 3\n",
    "\n",
    "    # vocabulary\n",
    "    low, lower, newest, widest\n",
    "\n",
    "        ↓\n",
    "\n",
    "    # dictionary\n",
    "    l o w : 5,  l o w e r : 2,  n e w e s t : 6,  w i d e s t : 3\n",
    "    \n",
    "    # vocabulary\n",
    "    l, o, w, e, r, n, s, t, i, d\n",
    "\n",
    "        ↓ (1st update, \"(e, s)\" is the most frequent pair)\n",
    "\n",
    "    # dictionary update\n",
    "    l o w : 5,\n",
    "    l o w e r : 2,\n",
    "    n e w es t : 6,\n",
    "    w i d es t : 3\n",
    "\n",
    "    # vocabulary update\n",
    "    l, o, w, e, r, n, s, t, i, d, es\n",
    "\n",
    "        ↓ (2nd update, \"(es, t)\" is the most frequent pair)\n",
    "\n",
    "    # dictionary update\n",
    "    l o w : 5,\n",
    "    l o w e r : 2,\n",
    "    n e w es t : 6,\n",
    "    w i d es t : 3\n",
    "\n",
    "    # vocabulary update\n",
    "    l, o, w, e, r, n, s, t, i, d, es, est\n",
    "\n",
    "    ↓ (3rd update, \"(l, o)\" is the most frequent pair)\n",
    "\n",
    "    # dictionary update\n",
    "    l o w : 5,\n",
    "    l o w e r : 2,\n",
    "    n e w es t : 6,\n",
    "    w i d es t : 3\n",
    "\n",
    "    # vocabulary update\n",
    "    l, o, w, e, r, n, s, t, i, d, es, est, lo\n",
    "\n",
    "    ...\n",
    "    ```\n",
    "\n",
    "References:\n",
    "- [Neural Machine Translation of Rare Words with Subword Units]\n",
    "\n",
    "\n",
    "[Neural Machine Translation of Rare Words with Subword Units]: https://arxiv.org/abs/1508.07909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec878a2c-7c0f-45c3-b951-c08b23194ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(dictionary: Dict[str, int]) -> Dict[str, int]:\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in dictionary.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i], symbols[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def merge_dictionary(pair: Tuple[str, str], v_in: Dict[str, int]) -> Dict[str, int]:\n",
    "    v_out = {}\n",
    "    bigram = re.escape(\" \".join(pair))\n",
    "    # (?<!\\S) => negative lookbehind\n",
    "    #   - ?<!X: case where there's no X right in front of the current location\n",
    "    #   - \\S: non-white-space character\n",
    "    # (?!\\S) => negative lookahead\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(\"\".join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92593b63-509c-4b16-addc-2764d29f022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_merges = 10\n",
    "\n",
    "dictionary = {\n",
    "    \"l o w </w>\": 5,\n",
    "    \"l o w e r </w>\": 2,\n",
    "    \"n e w e s t </w>\": 6,\n",
    "    \"w i d e s t </w>\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35262463-b121-4131-8806-8de82d8dd6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('l', 'o'): 7,\n",
       "             ('o', 'w'): 7,\n",
       "             ('w', '</w>'): 5,\n",
       "             ('w', 'e'): 8,\n",
       "             ('e', 'r'): 2,\n",
       "             ('r', '</w>'): 2,\n",
       "             ('n', 'e'): 6,\n",
       "             ('e', 'w'): 6,\n",
       "             ('e', 's'): 9,\n",
       "             ('s', 't'): 9,\n",
       "             ('t', '</w>'): 9,\n",
       "             ('w', 'i'): 3,\n",
       "             ('i', 'd'): 3,\n",
       "             ('d', 'e'): 3})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1776851-70e4-4bc3-9f46-01f39d24d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_codes = {}\n",
    "bpe_codes_reverse = {}\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(dictionary)\n",
    "    most_frequent_pair = max(pairs, key=pairs.get)\n",
    "    \n",
    "    dictionary = merge_dictionary(most_frequent_pair, dictionary)\n",
    "\n",
    "    bpe_codes[most_frequent_pair] = i\n",
    "    bpe_codes_reverse[\"\".join(most_frequent_pair)] = most_frequent_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb69c376-c5bd-4c2a-8b83-2af75d05214b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('low', 'e'): 2,\n",
       "             ('e', 'r'): 2,\n",
       "             ('r', '</w>'): 2,\n",
       "             ('wi', 'd'): 3,\n",
       "             ('d', 'est</w>'): 3})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230cf0e1-fddb-4119-b158-52e1c50aa917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('e', 's'): 0,\n",
       " ('es', 't'): 1,\n",
       " ('est', '</w>'): 2,\n",
       " ('l', 'o'): 3,\n",
       " ('lo', 'w'): 4,\n",
       " ('n', 'e'): 5,\n",
       " ('ne', 'w'): 6,\n",
       " ('new', 'est</w>'): 7,\n",
       " ('low', '</w>'): 8,\n",
       " ('w', 'i'): 9}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4368e7a5-b580-4de1-b386-84a444b4a268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'es': ('e', 's'),\n",
       " 'est': ('es', 't'),\n",
       " 'est</w>': ('est', '</w>'),\n",
       " 'lo': ('l', 'o'),\n",
       " 'low': ('lo', 'w'),\n",
       " 'ne': ('n', 'e'),\n",
       " 'new': ('ne', 'w'),\n",
       " 'newest</w>': ('new', 'est</w>'),\n",
       " 'low</w>': ('low', '</w>'),\n",
       " 'wi': ('w', 'i')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_codes_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad453c-69ea-4ee9-adca-be02e595f491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ffa70e-a469-4f72-9463-0f7c697cfdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(word: Tuple[str]) -> Set[str]:\n",
    "    \"\"\"Return set of symbol pairs in a word.\n",
    "    Word is represented as a tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    if not word:\n",
    "        return set()\n",
    "    \n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def encode(word: str, bpe_codes: Dict[str, int]) ->  Tuple[str]:\n",
    "    \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\"\"\"\n",
    "\n",
    "    # e.g. word=\"loki\"\n",
    "    #  - chars = (\"l\", \"o\", \"k\", \"i\", \"</w>\")\n",
    "    #  - pairs = ((\"l\", \"o\"), (\"o\", \"k\"), (\"k\", \"i\"), (\"i\", \"</w>\"))\n",
    "    chars = tuple(word) + (\"</w>\", )\n",
    "    pairs = get_pairs(word)\n",
    "\n",
    "    if not pairs:\n",
    "        return word\n",
    "\n",
    "    num_iter = 0\n",
    "    while True:\n",
    "        num_iter += 1        \n",
    "        bigram = min(pairs, key=lambda pair: bpe_codes.get(pair, float(\"inf\")))\n",
    "\n",
    "        # there's no further merge\n",
    "        if bigram not in bpe_codes:\n",
    "            break\n",
    "        \n",
    "        c1, c2 = bigram\n",
    "        new = []\n",
    "        i = 0\n",
    "        while i < len(chars):\n",
    "            cur = chars[i]\n",
    "            # update i until cur == c1\n",
    "            if c1 != cur:\n",
    "                new.append(cur)\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # in case of (..., c1, c2, ...), merge c1 and c2\n",
    "            #                  i       next \n",
    "            if c1 == cur and i < len(chars)-1 and c2 == chars[i+1]:                \n",
    "                new.append(c1+c2)\n",
    "                i += 2\n",
    "            # in case of (..., c1, c3, ...), where c2 != c3\n",
    "            #                  i   next\n",
    "            else:\n",
    "                new.append(c1)\n",
    "                i += 1\n",
    "\n",
    "        chars = tuple(new)\n",
    "        if len(chars) == 1:\n",
    "            break\n",
    "        else:\n",
    "            pairs = get_pairs(chars)\n",
    "\n",
    "    # ignore </w> token\n",
    "    if chars[-1] == \"</w>\":\n",
    "        chars = chars[:-1]\n",
    "    elif chars[-1].endswith(\"</w>\"):\n",
    "        chars = chars[:-1] + (chars[-1].replace(\"</w>\", \"\"),)\n",
    "\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a8617c7-7d14-43b4-8a5c-6124d397c5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"\", bpe_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7fd50c2-1085-4608-bf20-0e83ccfd933c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lo', 'k', 'i')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"loki\", bpe_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2776e08-f1f8-40fc-803c-0bb14923191b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('low', 'est')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"lowest\", bpe_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8296fcf-36e7-4470-bc3f-34a7cacc1e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('low', 'i', 'n', 'g')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"lowing\", bpe_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bf4a564-3acb-4583-becc-3347684d3e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('h', 'i', 'g', 'h', 'i', 'n', 'g')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"highing\", bpe_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41caef4e-2210-4fcd-8189-174067845097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ce88a-8bf6-449c-b85e-dedba7996c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e075791d-7edf-40b8-ac0e-5cf7abe1c8ea",
   "metadata": {},
   "source": [
    "## 2. SentencePiece\n",
    "Sentencepiece is an open-source library developed by google for splitting subword.  \n",
    "Since Sentencepice does not require pre-tokenization and uses only the raw data, it can be applied to all languages.\n",
    "\n",
    "\n",
    "References:\n",
    "- [SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing]\n",
    "- [sentencepiece Github]\n",
    "\n",
    "[SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing]: https://arxiv.org/pdf/1808.06226\n",
    "[sentencepiece Github]: https://github.com/google/sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37410b4a-784e-4e96-ab9d-2e52c4e8d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "import pandas as pd\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70067197-2d13-4fe9-b074-4990cfb0bfaf",
   "metadata": {},
   "source": [
    "### 2-1. IMDB Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "296b99c9-022c-4e52-b12a-23e684d34cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "imdb_csv_path = os.path.join(data_dir, \"imdb_review.csv\")\n",
    "imdb_txt_path = os.path.join(data_dir, \"imdb_review.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "618d00e2-9643-40d0-9007-90517996b022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/imdb_review.csv', <http.client.HTTPMessage at 0x7feb901462e0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\",\n",
    "    filename=imdb_csv_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0220a89f-20ec-402e-aced-09b79bf4b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(imdb_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ecdf253-101a-4151-96f7-5e65fa6826bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3b2f2b2-7b06-4af8-b7bb-8c67ee59930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb401591-3e44-49c7-ac17-97640a595f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df as text file (sentencepiece requires .txt input file)\n",
    "\n",
    "with open(imdb_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(df_train.review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fac6fe52-c1d0-4832-8339-8e60b271c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=../data/imdb_review.txt --model_prefix=imdb --vocab_size=5000 --model_type=bpe --max_sentence_length=9999\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../data/imdb_review.txt\n",
      "  input_format: \n",
      "  model_prefix: imdb\n",
      "  model_type: BPE\n",
      "  vocab_size: 5000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 9999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ../data/imdb_review.txt\n",
      "trainer_interface.cc(380) LOG(WARNING) Found too long line (10321 > 9999).\n",
      "trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 49994 sentences\n",
      "trainer_interface.cc(416) LOG(INFO) Skipped 6 too long sentences.\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=65449658\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9552% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=76\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999552\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 49994 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 49994\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 438648\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1557312 min_freq=373\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=384101 size=20 all=3611 active=1972 piece=en\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=220588 size=40 all=4932 active=3293 piece=om\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=158358 size=60 all=6355 active=4716 piece=ie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=106638 size=80 all=7931 active=6292 piece=id\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90444 size=100 all=9108 active=7469 piece=am\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=90105 min_freq=5590\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65629 size=120 all=10552 active=2264 piece=ally\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54599 size=140 all=11902 active=3614 piece=▁have\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47018 size=160 all=13192 active=4904 piece=▁k\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41819 size=180 all=14928 active=6640 piece=ol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37033 size=200 all=16837 active=8549 piece=ven\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=37018 min_freq=4995\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34053 size=220 all=18236 active=2327 piece=▁me\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30398 size=240 all=19803 active=3894 piece=▁un\n",
      "260 all=21138 active=5229 piece=▁getAdded: freq=27178 size=\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24165 size=280 all=21984 active=6075 piece=▁bec\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22036 size=300 all=22865 active=6956 piece=▁watch\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22031 min_freq=3786\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20573 size=320 all=24298 active=2568 piece=▁kn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19165 size=340 all=26041 active=4311 piece=▁pe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18034 size=360 all=26899 active=5169 piece=▁how\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16799 size=380 all=27926 active=6196 piece=other\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15869 size=400 all=29087 active=7357 piece=▁direct\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15837 min_freq=2654\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14689 size=420 all=30336 active=2691 piece=��movies\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13994 size=440 all=31414 active=3769 piece=ob\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13210 size=460 all=32677 active=5032 piece=▁plot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12444 size=480 all=33129 active=5484 piece=ittle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11855 size=500 all=34392 active=6747 piece=ved\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11779 min_freq=2013\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11066 size=520 all=35367 active=2659 piece=▁br\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10278 size=540 all=36441 active=3733 piece=vers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9987 size=560 all=37360 active=4652 piece=augh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9449 size=580 all=38291 active=5583 piece=ense\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8980 size=600 all=39016 active=6308 piece=▁performan\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8915 min_freq=1643\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8632 size=620 all=39980 active=2913 piece=▁ap\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8202 size=640 all=40330 active=3263 piece=▁set\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7865 size=660 all=41238 active=4171 piece=▁few\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7528 size=680 all=42014 active=4947 piece=▁got\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7345 size=700 all=42491 active=5424 piece=▁Jo\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7344 min_freq=1382\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7043 size=720 all=43424 active=3029 piece=▁effect\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6745 size=740 all=43985 active=3590 piece=ched\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6523 size=760 all=44838 active=4443 piece=▁high\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6354 size=780 all=45455 active=5060 piece=▁give\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6125 size=800 all=46095 active=5700 piece=▁put\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6123 min_freq=1214\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6012 size=820 all=46378 active=2570 piece=oot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5812 size=840 all=46847 active=3039 piece=▁cons\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5653 size=860 all=47420 active=3612 piece=▁expl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5434 size=880 all=48074 active=4266 piece=▁help\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5215 size=900 all=48753 active=4945 piece=oney\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5199 min_freq=1094\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5050 size=920 all=49421 active=3072 piece=This\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4922 size=940 all=50658 active=4309 piece=▁worst\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4820 size=960 all=50989 active=4640 piece=▁episod\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4686 size=980 all=51744 active=5395 piece=▁job\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4568 size=1000 all=52338 active=5989 piece=▁ty\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4568 min_freq=961\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4487 size=1020 all=52887 active=3155 piece=ray\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4390 size=1040 all=53364 active=3632 piece=▁money\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4303 size=1060 all=54345 active=4613 piece=....\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4198 size=1080 all=54980 active=5248 piece=▁having\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4079 size=1100 all=55278 active=5546 piece=not\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4078 min_freq=872\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4025 size=1120 all=55901 active=3335 piece=▁American\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3935 size=1140 all=56651 active=4085 piece=▁invol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3813 size=1160 all=57291 active=4725 piece=▁Un\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3755 size=1180 all=57769 active=5203 piece=▁low\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3658 size=1200 all=58430 active=5864 piece=ains\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3650 min_freq=783\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3573 size=1220 all=59095 active=3539 piece=▁exp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3490 size=1240 all=59668 active=4112 piece=▁along\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3408 size=1260 all=59983 active=4427 piece=▁dra\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3329 size=1280 all=60633 active=5077 piece=▁exam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3280 size=1300 all=61064 active=5508 piece=med\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3279 min_freq=720\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3220 size=1320 all=61412 active=3340 piece=▁hero\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3157 size=1340 all=61960 active=3888 piece=▁instead\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3045 size=1360 all=62710 active=4638 piece=▁doing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3008 size=1380 all=63183 active=5111 piece=reme\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2941 size=1400 all=63669 active=5597 piece=▁cor\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2937 min_freq=664\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2884 size=1420 all=64126 active=3614 piece=▁develop\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2818 size=1440 all=64656 active=4144 piece=▁stars\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2755 size=1460 all=65242 active=4730 piece=ccess\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2690 size=1480 all=65728 active=5216 piece=▁seemed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2647 size=1500 all=66048 active=5536 piece=▁several\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2644 min_freq=619\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2597 size=1520 all=66481 active=3736 piece=▁adm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2549 size=1540 all=66935 active=4190 piece=▁although\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2491 size=1560 all=67431 active=4686 piece=▁self\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2442 size=1580 all=67862 active=5117 piece=▁Char\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2403 size=1600 all=68268 active=5523 piece=sych\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2399 min_freq=578\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2370 size=1620 all=68618 active=3739 piece=▁mag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2327 size=1640 all=69221 active=4342 piece=▁stra\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2294 size=1660 all=69644 active=4765 piece=▁contin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2260 size=1680 all=69946 active=5067 piece=▁Robert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2224 size=1700 all=70427 active=5548 piece=▁opp\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2224 min_freq=544\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2193 size=1720 all=70896 active=3981 piece=▁decent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2151 size=1740 all=71320 active=4405 piece=ys\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2109 size=1760 all=71900 active=4985 piece=▁tele\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2078 size=1780 all=72384 active=5469 piece=ters\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2047 size=1800 all=72878 active=5963 piece=aves\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2047 min_freq=509\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2019 size=1820 all=73307 active=4037 piece=▁uni\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1992 size=1840 all=73580 active=4310 piece=rench\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1968 size=1860 all=74252 active=4982 piece=cer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1941 size=1880 all=75104 active=5834 piece=▁known\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1916 size=1900 all=75692 active=6422 piece=▁highly\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1915 min_freq=475\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1883 size=1920 all=75841 active=3934 piece=▁yourself\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1862 size=1940 all=76110 active=4203 piece=ubl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1843 size=1960 all=76576 active=4669 piece=▁writer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1814 size=1980 all=76919 active=5012 piece=bel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1798 size=2000 all=77360 active=5453 piece=▁moder\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1797 min_freq=452\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1780 size=2020 all=77498 active=3996 piece=▁turned\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1748 size=2040 all=77953 active=4451 piece=ald\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1716 size=2060 all=78455 active=4953 piece=lt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1703 size=2080 all=79062 active=5560 piece=▁among\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1676 size=2100 all=79338 active=5836 piece=EN\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1676 min_freq=427\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1654 size=2120 all=79631 active=4189 piece=lo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1624 size=2140 all=80075 active=4633 piece=▁sets\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1602 size=2160 all=80421 active=4979 piece=▁upon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1581 size=2180 all=80746 active=5304 piece=▁clearly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1562 size=2200 all=80931 active=5489 piece=▁feature\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1560 min_freq=409\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1542 size=2220 all=81278 active=4392 piece=▁showing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1522 size=2240 all=81672 active=4786 piece=ltim\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1504 size=2260 all=82115 active=5229 piece=▁George\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1491 size=2280 all=82571 active=5685 piece=▁easy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1474 size=2300 all=82834 active=5948 piece=upp\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1473 min_freq=387\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1450 size=2320 all=83095 active=4348 piece=▁Richard\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1433 size=2340 all=83341 active=4594 piece=▁truth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1409 size=2360 all=83907 active=5160 piece=lin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1398 size=2380 all=84329 active=5582 piece=▁city\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1376 size=2400 all=84528 active=5781 piece=▁sens\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1373 min_freq=370\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1360 size=2420 all=85042 active=4721 piece=▁wait\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1339 size=2440 all=85412 active=5091 piece=▁Peter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1322 size=2460 all=85768 active=5447 piece=▁utter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1309 size=2480 all=86027 active=5706 piece=▁lame\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1296 size=2500 all=86374 active=6053 piece=▁Com\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1296 min_freq=352\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1279 size=2520 all=86796 active=4708 piece=▁monster\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1262 size=2540 all=87211 active=5123 piece=▁perfectly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1250 size=2560 all=87549 active=5461 piece=▁Par\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1240 size=2580 all=87903 active=5815 piece=▁law\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1227 size=2600 all=88309 active=6221 piece=My\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1227 min_freq=337\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1214 size=2620 all=88696 active=4789 piece=▁conne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1202 size=2640 all=89060 active=5153 piece=allow\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1191 size=2660 all=89335 active=5428 piece=▁incredibly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1179 size=2680 all=89740 active=5833 piece=▁conv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1165 size=2700 all=90011 active=6104 piece=▁occas\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1165 min_freq=324\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1152 size=2720 all=90351 active=4838 piece=▁invest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1140 size=2740 all=90728 active=5215 piece=▁manages\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1122 size=2760 all=91194 active=5681 piece=▁langu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1109 size=2780 all=91436 active=5923 piece=mist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1099 size=2800 all=91710 active=6197 piece=▁fighting\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1096 min_freq=310\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1088 size=2820 all=92153 active=5029 piece=▁outside\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1078 size=2840 all=92542 active=5418 piece=▁30\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1067 size=2860 all=92815 active=5691 piece=▁Other\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1058 size=2880 all=93052 active=5928 piece=IS\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1047 size=2900 all=93391 active=6267 piece=▁former\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1046 min_freq=297\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1038 size=2920 all=93661 active=4939 piece=▁hardly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1029 size=2940 all=93886 active=5164 piece=ging\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1020 size=2960 all=94303 active=5581 piece=▁accent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1008 size=2980 all=94523 active=5801 piece=▁rate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=999 size=3000 all=94949 active=6227 piece=inger\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=999 min_freq=284\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=984 size=3020 all=95332 active=5082 piece=this\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=972 size=3040 all=95633 active=5383 piece=▁ground\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=965 size=3060 all=95961 active=5711 piece=▁humour\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=954 size=3080 all=96303 active=6053 piece=ribly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=944 size=3100 all=96676 active=6426 piece=▁otherwise\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=943 min_freq=274\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=939 size=3120 all=96859 active=5017 piece=▁changed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=928 size=3140 all=96967 active=5125 piece=▁Love\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=915 size=3160 all=97266 active=5424 piece=▁suc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=909 size=3180 all=97465 active=5623 piece=▁suddenly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=902 size=3200 all=97669 active=5827 piece=▁trash\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=901 min_freq=268\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=893 size=3220 all=97834 active=5042 piece=ales\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=887 size=3240 all=98305 active=5513 piece=▁repl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=878 size=3260 all=98613 active=5821 piece=▁govern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=872 size=3280 all=98794 active=6002 piece=▁House\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=864 size=3300 all=99109 active=6317 piece=▁fashion\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=863 min_freq=259\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=857 size=3320 all=99498 active=5339 piece=lessly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=848 size=3340 all=99939 active=5780 piece=▁smart\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=841 size=3360 all=100366 active=6207 piece=▁sav\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=833 size=3380 all=100548 active=6389 piece=▁Bat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=827 size=3400 all=100758 active=6599 piece=▁soldiers\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=826 min_freq=249\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=819 size=3420 all=100893 active=5173 piece=▁Austral\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=814 size=3440 all=101090 active=5370 piece=▁emotions\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=807 size=3460 all=101301 active=5581 piece=▁charming\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=800 size=3480 all=101521 active=5801 piece=▁High\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=795 size=3500 all=101803 active=6083 piece=▁historical\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=794 min_freq=242\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=787 size=3520 all=102019 active=5307 piece=arsh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=780 size=3540 all=102203 active=5491 piece=field\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=773 size=3560 all=102483 active=5771 piece=▁soft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=767 size=3580 all=102746 active=6034 piece=▁makers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=760 size=3600 all=103035 active=6323 piece=CH\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=759 min_freq=235\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=754 size=3620 all=103296 active=5350 piece=▁element\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=748 size=3640 all=103429 active=5483 piece=▁current\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=742 size=3660 all=103734 active=5788 piece=▁drive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=733 size=3680 all=104079 active=6133 piece=▁Yet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=728 size=3700 all=104262 active=6316 piece=▁students\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=727 min_freq=228\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=722 size=3720 all=104656 active=5608 piece=▁irrit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=714 size=3740 all=104904 active=5856 piece=▁trag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=710 size=3760 all=105065 active=6017 piece=▁drawn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=704 size=3780 all=105248 active=6200 piece=▁confused\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=699 size=3800 all=105546 active=6498 piece=▁hospital\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=698 min_freq=222\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=693 size=3820 all=105868 active=5596 piece=▁delivers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=687 size=3840 all=106210 active=5938 piece=▁paid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=683 size=3860 all=106448 active=6176 piece=▁anymore\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=676 size=3880 all=106621 active=6349 piece=azz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=672 size=3900 all=106986 active=6714 piece=▁bi\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=672 min_freq=216\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=669 size=3920 all=107192 active=5540 piece=▁market\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=664 size=3940 all=107352 active=5700 piece=----\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=661 size=3960 all=107606 active=5954 piece=▁mediocre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=657 size=3980 all=107916 active=6264 piece=stein\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=652 size=4000 all=108207 active=6555 piece=she\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=652 min_freq=211\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=649 size=4020 all=108425 active=5601 piece=iday\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=646 size=4040 all=108612 active=5788 piece=athetic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=641 size=4060 all=108924 active=6100 piece=▁/>-\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=637 size=4080 all=109090 active=6266 piece=▁professional\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=632 size=4100 all=109391 active=6567 piece=herent\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=632 min_freq=205\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=626 size=4120 all=109568 active=5638 piece=requ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=620 size=4140 all=109810 active=5880 piece=▁angry\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=615 size=4160 all=110016 active=6086 piece=▁Once\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=611 size=4180 all=110380 active=6450 piece=ovies\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=608 size=4200 all=110593 active=6663 piece=▁favourite\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=607 min_freq=200\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=603 size=4220 all=110870 active=5807 piece=▁epic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=599 size=4240 all=111175 active=6112 piece=▁numbers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=596 size=4260 all=111371 active=6308 piece=▁brutal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=591 size=4280 all=111435 active=6372 piece=▁anywhere\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=587 size=4300 all=111683 active=6620 piece=▁rape\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=587 min_freq=195\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=583 size=4320 all=111870 active=5768 piece=▁IN\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=580 size=4340 all=112088 active=5986 piece=▁Wal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=575 size=4360 all=112329 active=6227 piece=AM\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=570 size=4380 all=112744 active=6642 piece=▁ted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=567 size=4400 all=112963 active=6861 piece=pective\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=567 min_freq=190\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=563 size=4420 all=113192 active=5874 piece=hand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=559 size=4440 all=113402 active=6084 piece=ET\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=557 size=4460 all=113580 active=6262 piece=▁hurt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=553 size=4480 all=113825 active=6507 piece=▁Sus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=549 size=4500 all=113976 active=6658 piece=ipul\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=549 min_freq=185\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=546 size=4520 all=114221 active=5927 piece=▁tight\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=542 size=4540 all=114435 active=6141 piece=star\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=539 size=4560 all=114626 active=6332 piece=unter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=535 size=4580 all=114875 active=6581 piece=John\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=532 size=4600 all=115057 active=6763 piece=ennifer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=532 min_freq=182\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=529 size=4620 all=115218 active=5909 piece=▁fights\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=526 size=4640 all=115360 active=6051 piece=▁stret\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=523 size=4660 all=115615 active=6306 piece=▁capture\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=520 size=4680 all=115852 active=6543 piece=▁net\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=517 size=4700 all=115978 active=6669 piece=▁finest\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=516 min_freq=177\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=513 size=4720 all=116127 active=5948 piece=viron\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=511 size=4740 all=116361 active=6182 piece=▁incomp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=507 size=4760 all=116494 active=6315 piece=screen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=503 size=4780 all=116903 active=6724 piece=▁guns\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=501 size=4800 all=117032 active=6853 piece=▁terribly\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=500 min_freq=173\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=497 size=4820 all=117325 active=6145 piece=unn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=495 size=4840 all=117594 active=6414 piece=▁toward\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=492 size=4860 all=117911 active=6731 piece=edding\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=489 size=4880 all=118123 active=6943 piece=▁levels\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=487 size=4900 all=118232 active=7052 piece=▁attitude\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=486 min_freq=168\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=484 size=4920 all=118461 active=6141 piece=▁kiss\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: imdb.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: imdb.vocab\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Args:\n",
    "- input: train data\n",
    "- model_prefix: model name\n",
    "- vocab_size: size of the vocabulary\n",
    "- model_tyep: one of unigram(default), bpe, char, word\n",
    "- max_sentence_length: maximum length of senetence\n",
    "- pad_id, pad_piece: pad token id, value\n",
    "- unk_id, unk_piece: unknown token id, value\n",
    "- bos_id, bos_piece: begin of sentence token id, value\n",
    "- eos_id, eos_piece: end of sequence token id, value\n",
    "- user_defined_symbols: user defined token\n",
    "\n",
    "Returns:\n",
    "- {model_prefix}.vocab\n",
    "- {model_prefix}.model\n",
    "\"\"\"\n",
    "\n",
    "spm.SentencePieceTrainer.Train(f\"--input={imdb_txt_path} --model_prefix=imdb --vocab_size=5000 --model_type=bpe --max_sentence_length=9999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd51d3f0-6d0d-445f-8f49-91c047de807d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>belie</td>\n",
       "      <td>-2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>set</td>\n",
       "      <td>-2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>▁top</td>\n",
       "      <td>-1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>▁fant</td>\n",
       "      <td>-1483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>▁chick</td>\n",
       "      <td>-4283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>▁clim</td>\n",
       "      <td>-2388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4911</th>\n",
       "      <td>▁Chan</td>\n",
       "      <td>-4908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>▁govern</td>\n",
       "      <td>-3259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>▁guess</td>\n",
       "      <td>-1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>▁j</td>\n",
       "      <td>-146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1\n",
       "2706    belie -2703\n",
       "2436      set -2433\n",
       "1201     ▁top -1198\n",
       "1486    ▁fant -1483\n",
       "4286   ▁chick -4283\n",
       "2391    ▁clim -2388\n",
       "4911    ▁Chan -4908\n",
       "3262  ▁govern -3259\n",
       "1361   ▁guess -1358\n",
       "149        ▁j  -146"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = pd.read_csv(\"./imdb.vocab\", sep=\"\\t\", header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list.sample(10, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "288cd268-b0ad-48db-bb90-fa174be6212d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that the vocab_size to train SentencePiece was 5,000\n",
    "\n",
    "vocab_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c194e039-73ff-408f-86ae-69d8f259e800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = \"imdb.model\"\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "645faca3-472e-4989-8ae1-498a84c4d4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't at all think of it this way.\n",
      "['▁I', '▁didn', \"'\", 't', '▁at', '▁all', '▁think', '▁of', '▁it', '▁this', '▁way', '.']\n",
      "[41, 624, 4950, 4926, 139, 170, 378, 30, 58, 73, 413, 4945]\n",
      "\n",
      "I have waited a long time for some to film\n",
      "['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁some', '▁to', '▁film']\n",
      "[41, 142, 1364, 1121, 4, 668, 285, 93, 205, 33, 91]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "    \"I didn't at all think of it this way.\",\n",
    "    \"I have waited a long time for some to film\",\n",
    "]\n",
    "\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    print(sp.encode_as_pieces(line))\n",
    "    print(sp.encode_as_ids(line))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f38a47-ee13-4b19-84eb-8c08c113ae57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c062be73-5900-46e0-9aed-3bfb15b37c1c",
   "metadata": {},
   "source": [
    "### 2-2. Naver Movie Review Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e90fbc70-4d85-49b4-a6ea-9d48a354483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "naver_movie_csv_path = os.path.join(data_dir, \"naver_movie_review.csv\")\n",
    "naver_movie_txt_path = os.path.join(data_dir, \"naver_movie_review.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d86f9e0b-c4b2-4f8f-83a6-21bb6d738038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/naver_movie_review.csv', <http.client.HTTPMessage at 0x7feb57ea1340>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\",\n",
    "    filename=naver_movie_csv_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40f7d5f1-c375-48ed-853e-47ce28f0592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(naver_movie_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "020d0db3-6d11-43e0-b2dc-097a38d0ca12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79ead4ce-e157-44b4-9b7a-0a3da781d2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27ae4252-abb4-47a7-a15e-88d3c47060f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: document contains null values\n",
    "\n",
    "df.dropna(how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7153c5ff-cb47-4224-b65c-16a6eb4c137f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199992, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b385f3d-df10-4055-bfd9-4189a5c20192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df as text file (sentencepiece requires .txt input file)\n",
    "\n",
    "with open(naver_movie_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(df.document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "099d670c-3d54-470f-9aec-665bcf07bab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=../data/naver_movie_review.txt --model_prefix=naver --vocab_size=5000 --model_type=bpe --max_sentence_length=9999\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../data/naver_movie_review.txt\n",
      "  input_format: \n",
      "  model_prefix: naver\n",
      "  model_type: BPE\n",
      "  vocab_size: 5000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 9999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ../data/naver_movie_review.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 199992 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=7242982\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=1725\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 199992 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 199992\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 449380\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=145835 min_freq=100\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15293 size=20 all=124333 active=11699 piece=▁없\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11921 size=40 all=129320 active=16686 piece=▁1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8425 size=60 all=133224 active=20590 piece=▁생\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7026 size=80 all=137895 active=25261 piece=▁배\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5692 size=100 all=141885 active=29251 piece=하게\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5660 min_freq=83\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4959 size=120 all=145494 active=10211 piece=▁중\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4472 size=140 all=148078 active=12795 piece=▁끝\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3830 size=160 all=150805 active=15522 piece=▁영\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3596 size=180 all=153693 active=18410 piece=▁좋은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3227 size=200 all=156373 active=21090 piece=▁기대\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3219 min_freq=75\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2983 size=220 all=158712 active=10082 piece=야기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2772 size=240 all=161819 active=13189 piece=▁현\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2580 size=260 all=164836 active=16206 piece=부터\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2414 size=280 all=168187 active=19557 piece=▁심\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2268 size=300 all=170138 active=21508 piece=▁괜찮\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2251 min_freq=67\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2087 size=320 all=172399 active=10728 piece=리는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1941 size=340 all=174678 active=13007 piece=것도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1856 size=360 all=177272 active=15601 piece=▁표\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1781 size=380 all=179752 active=18081 piece=하기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1694 size=400 all=182457 active=20786 piece=▁반전\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1687 min_freq=62\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1642 size=420 all=184396 active=10974 piece=▁얼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1564 size=440 all=186431 active=13009 piece=▁인간\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1490 size=460 all=188816 active=15394 piece=▁솔직\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1435 size=480 all=190437 active=17015 piece=▁굿\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1376 size=500 all=192599 active=19177 piece=었음\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1367 min_freq=57\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1313 size=520 all=194430 active=11327 piece=▁파\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1249 size=540 all=196073 active=12970 piece=기도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1209 size=560 all=198224 active=15121 piece=▁공감\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1176 size=580 all=200718 active=17615 piece=때문에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1142 size=600 all=203465 active=20362 piece=▁영화에\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1141 min_freq=53\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1113 size=620 all=205648 active=12333 piece=기는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1071 size=640 all=208057 active=14742 piece=▁싸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1044 size=660 all=210144 active=16829 piece=▁조금\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1012 size=680 all=212391 active=19076 piece=하면서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=980 size=700 all=214450 active=21135 piece=대체\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=979 min_freq=49\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=955 size=720 all=216122 active=12343 piece=▁제작\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=929 size=740 all=217887 active=14108 piece=▁웃기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=896 size=760 all=218986 active=15207 piece=▁영화라고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=868 size=780 all=220756 active=16977 piece=▁출연\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=854 size=800 all=222279 active=18500 piece=적이고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=852 min_freq=47\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=832 size=820 all=223990 active=12684 piece=▁싫\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=821 size=840 all=225215 active=13909 piece=▁무섭\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=798 size=860 all=226603 active=15297 piece=▁ᅲ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=778 size=880 all=228086 active=16780 piece=▁좋아하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=765 size=900 all=229344 active=18038 piece=▁봤던\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=764 min_freq=45\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=749 size=920 all=230783 active=12891 piece=▁킬링\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=731 size=940 all=232105 active=14213 piece=▁지루하고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=719 size=960 all=233502 active=15610 piece=구만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=705 size=980 all=234590 active=16698 piece=▁큰\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=686 size=1000 all=235694 active=17802 piece=▁암\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=686 min_freq=43\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=673 size=1020 all=237168 active=13193 piece=보단\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=663 size=1040 all=238688 active=14713 piece=▁지루하다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=643 size=1060 all=240592 active=16617 piece=▁더빙\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=627 size=1080 all=242021 active=18046 piece=▁한국영화\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=614 size=1100 all=243598 active=19623 piece=▁꽤\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=614 min_freq=41\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=600 size=1120 all=244887 active=13444 piece=말이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=587 size=1140 all=246112 active=14669 piece=▁감동적이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=576 size=1160 all=247397 active=15954 piece=▁하지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=563 size=1180 all=248980 active=17537 piece=▁이쁘\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=552 size=1200 all=250470 active=19027 piece=▁영상미\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=551 min_freq=39\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=541 size=1220 all=252001 active=14016 piece=것을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=526 size=1240 all=253334 active=15349 piece=▁g\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=516 size=1260 all=254953 active=16968 piece=▁기억이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=509 size=1280 all=256157 active=18172 piece=▁비디오\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=500 size=1300 all=258087 active=20102 piece=▁한마디\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=499 min_freq=37\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=488 size=1320 all=259296 active=14094 piece=개도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=478 size=1340 all=260519 active=15317 piece=으면서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=472 size=1360 all=261763 active=16561 piece=되고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=468 size=1380 all=263365 active=18163 piece=▁잘봤\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=463 size=1400 all=264654 active=19452 piece=▁전부\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=462 min_freq=36\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=454 size=1420 all=265929 active=14464 piece=▁여배우\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=445 size=1440 all=267347 active=15882 piece=▁중간에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=436 size=1460 all=268368 active=16903 piece=하자\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=429 size=1480 all=269451 active=17986 piece=▁자기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=423 size=1500 all=270279 active=18814 piece=▁재밌네요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=422 min_freq=35\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=416 size=1520 all=271916 active=15137 piece=▁압\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=409 size=1540 all=273252 active=16473 piece=▁감독님\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=400 size=1560 all=274314 active=17535 piece=예요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=394 size=1580 all=275327 active=18548 piece=▁항상\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=388 size=1600 all=276434 active=19655 piece=리의\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=388 min_freq=34\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=383 size=1620 all=277332 active=14596 piece=▁생각해\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=378 size=1640 all=278365 active=15629 piece=▁빌\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=373 size=1660 all=279763 active=17027 piece=봐서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=369 size=1680 all=280969 active=18233 piece=▁된다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=363 size=1700 all=281842 active=19106 piece=▁헤\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=363 min_freq=33\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=357 size=1720 all=283226 active=15431 piece=별로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=353 size=1740 all=284922 active=17127 piece=▁시절\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=349 size=1760 all=285798 active=18003 piece=▁없네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=345 size=1780 all=286909 active=19114 piece=▁홍콩\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=339 size=1800 all=288072 active=20277 piece=▁참신\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=339 min_freq=32\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=335 size=1820 all=288980 active=15276 piece=▁뮤\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=331 size=1840 all=290091 active=16387 piece=▁안나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=328 size=1860 all=291232 active=17528 piece=.......\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=323 size=1880 all=292581 active=18877 piece=▁후반부\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=320 size=1900 all=293584 active=19880 piece=영화로\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=320 min_freq=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=315 size=1920 all=294603 active=15542 piece=▁아버지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=311 size=1940 all=295441 active=16380 piece=▁희망\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=307 size=1960 all=296477 active=17416 piece=실망\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=304 size=1980 all=297674 active=18613 piece=▁흘러\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=301 size=2000 all=298464 active=19403 piece=▁신기\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=301 min_freq=30\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=297 size=2020 all=299604 active=16025 piece=▁나라\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=294 size=2040 all=300795 active=17216 piece=▁노출\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=289 size=2060 all=301609 active=18030 piece=▁즐겁\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=286 size=2080 all=302194 active=18615 piece=세가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=283 size=2100 all=303204 active=19625 piece=화가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=283 min_freq=29\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=280 size=2120 all=304368 active=16224 piece=▁부모\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=277 size=2140 all=305383 active=17239 piece=▁그의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=274 size=2160 all=306711 active=18567 piece=▁같네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=269 size=2180 all=307539 active=19395 piece=▁증\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=266 size=2200 all=308189 active=20045 piece=▁스케\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=266 min_freq=28\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=264 size=2220 all=309384 active=16596 piece=▁않을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=261 size=2240 all=310471 active=17683 piece=▁접\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=259 size=2260 all=311523 active=18735 piece=보이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=257 size=2280 all=312844 active=20056 piece=좋고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=254 size=2300 all=313649 active=20861 piece=▁밑에\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=254 min_freq=27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=252 size=2320 all=314886 active=16900 piece=▁가끔\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=250 size=2340 all=315771 active=17785 piece=▁심리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=248 size=2360 all=316838 active=18852 piece=▁눈이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=246 size=2380 all=317720 active=19734 piece=▁카메라\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=242 size=2400 all=318935 active=20949 piece=▁사람을\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=242 min_freq=27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=239 size=2420 all=319902 active=16906 piece=▁든다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=237 size=2440 all=320577 active=17581 piece=▁곳\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=235 size=2460 all=321365 active=18369 piece=도없고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=232 size=2480 all=322109 active=19113 piece=럭저럭\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=230 size=2500 all=322996 active=20000 piece=▁해주\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=230 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=227 size=2520 all=323690 active=16796 piece=▁꾸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=225 size=2540 all=324676 active=17782 piece=▁아까워\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=223 size=2560 all=325617 active=18723 piece=▁마라\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=222 size=2580 all=326407 active=19513 piece=▁그럭저럭\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=220 size=2600 all=327120 active=20226 piece=▁평생\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=220 min_freq=25\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=218 size=2620 all=327854 active=17063 piece=▁모자\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=216 size=2640 all=328962 active=18171 piece=▁상처\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=214 size=2660 all=329666 active=18875 piece=기로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=213 size=2680 all=330544 active=19753 piece=으로서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=211 size=2700 all=331319 active=20528 piece=▁사랑에\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=211 min_freq=25\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=209 size=2720 all=332039 active=17279 piece=▁고생\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=207 size=2740 all=332965 active=18205 piece=▁나타\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=205 size=2760 all=333629 active=18869 piece=▁썩\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=203 size=2780 all=334478 active=19718 piece=▁엘\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=202 size=2800 all=335748 active=20988 piece=▁형편\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=202 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=200 size=2820 all=336641 active=17671 piece=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=199 size=2840 all=337338 active=18368 piece=▁보시\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=198 size=2860 all=338100 active=19130 piece=▁설레\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=196 size=2880 all=339104 active=20134 piece=친다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=195 size=2900 all=340061 active=21091 piece=재미없\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=195 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=194 size=2920 all=341157 active=17969 piece=하시는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=192 size=2940 all=341817 active=18629 piece=▁건지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=191 size=2960 all=342787 active=19599 piece=▁봐야할\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=189 size=2980 all=343666 active=20478 piece=구니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=188 size=3000 all=344404 active=21216 piece=▁지구\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=188 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=186 size=3020 all=345397 active=18179 piece=▁지금은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=184 size=3040 all=346221 active=19003 piece=▁동물\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=182 size=3060 all=347000 active=19782 piece=re\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=181 size=3080 all=347990 active=20772 piece=점주\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=180 size=3100 all=348699 active=21481 piece=▁일부\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=180 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=178 size=3120 all=349305 active=18017 piece=하셨\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=177 size=3140 all=350037 active=18749 piece=이션\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=176 size=3160 all=350760 active=19472 piece=사의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=175 size=3180 all=351566 active=20278 piece=겠네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=174 size=3200 all=352331 active=21043 piece=내용도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=174 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=173 size=3220 all=353221 active=18413 piece=▁옛날에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=171 size=3240 all=353742 active=18934 piece=았고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=169 size=3260 all=354461 active=19653 piece=at\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: naver.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: naver.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train(f\"--input={naver_movie_txt_path} --model_prefix=naver --vocab_size=5000 --model_type=bpe --max_sentence_length=9999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25b8671c-15b1-4630-ae2a-fdce790b2333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>까진</td>\n",
       "      <td>-2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>▁넘어</td>\n",
       "      <td>-2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>이거</td>\n",
       "      <td>-1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>▁영화인데</td>\n",
       "      <td>-1483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>벅</td>\n",
       "      <td>-4283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>한건</td>\n",
       "      <td>-2388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4911</th>\n",
       "      <td>홥</td>\n",
       "      <td>-4908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>at</td>\n",
       "      <td>-3259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>감이</td>\n",
       "      <td>-1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>다는</td>\n",
       "      <td>-146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1\n",
       "2706     까진 -2703\n",
       "2436    ▁넘어 -2433\n",
       "1201     이거 -1198\n",
       "1486  ▁영화인데 -1483\n",
       "4286      벅 -4283\n",
       "2391     한건 -2388\n",
       "4911      홥 -4908\n",
       "3262     at -3259\n",
       "1361     감이 -1358\n",
       "149      다는  -146"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = pd.read_csv(\"./naver.vocab\", sep=\"\\t\", header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list.sample(10, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "511f7e08-969c-4bbc-b1db-a1f4d1364195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8daee7d1-0ae5-4342-9009-f50179e4c6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = \"./naver.model\"\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7884c89-7432-4d87-afaa-f754e65d9ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뭐 이딴 것도 영화냐.\n",
      "['▁뭐', '▁이딴', '▁것도', '▁영화냐', '.']\n",
      "[136, 970, 1299, 2593, 3276]\n",
      "\n",
      "진짜 최고의 영화입니다 ㅋㅋ\n",
      "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']\n",
      "[54, 204, 825, 121]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "  \"뭐 이딴 것도 영화냐.\",\n",
    "  \"진짜 최고의 영화입니다 ㅋㅋ\",\n",
    "]\n",
    "\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    print(sp.encode_as_pieces(line))\n",
    "    print(sp.encode_as_ids(line))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882bc5b0-f9be-417d-9ab6-f350b1eda41d",
   "metadata": {},
   "source": [
    "### 2-3. API guides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af29665b-98b7-45e1-b58d-a87b985bbb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns vocab size\n",
    "\n",
    "sp.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb207634-5bed-4fe6-91ae-f80083225a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'영화'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index to subword\n",
    "\n",
    "sp.IdToPiece(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2918d05a-d287-4606-8f21-c5fd86bd91b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subword to index\n",
    "\n",
    "sp.PieceToId(\"영화\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5965d0f-dc1c-420e-a4db-0c501297546b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'진짜 최고의 영화입니다 ᄏᄏ'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns sentence from the input integer sequence\n",
    "\n",
    "sp.DecodeIds([54, 204, 825, 121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8828b2cb-a33f-4cc5-94c6-368e818f8dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'진짜 최고의 영화입니다 ᄏᄏ'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns sentence from the input subword sequence\n",
    "\n",
    "sp.DecodePieces(['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f02d5009-c64c-4053-a0c1-574a74ab2c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns subword sequence from the input sentence\n",
    "\n",
    "sp.encode('진짜 최고의 영화입니다 ᄏᄏ', out_type=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ff300e9-b6f0-4ea1-93f0-2b079ad3ba25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54, 204, 825, 121]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns integer sequence from the input sentence\n",
    "\n",
    "sp.encode('진짜 최고의 영화입니다 ᄏᄏ', out_type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e38f34-5127-4c9c-b617-4d0f7a1dbaea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "346ef896-9c29-4919-82f5-e30c7014204b",
   "metadata": {},
   "source": [
    "## 3. SubwodTextEncoder\n",
    "SubwodTextEncoder is a subword tokenizer, which can be used through TensorFlow.  \n",
    "It uses Wordpiece Model, which is similar to BPE, and can easily split words into subwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b144a726-ce3d-4b22-846c-f23592348494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a62fcd67-0074-4018-a79f-cfda2735a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already downloaded imdb dataset in Section 2.\n",
    "data_dir = \"../data/\"\n",
    "\n",
    "imdb_csv_path = os.path.join(data_dir, \"imdb_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fe817b2-18a0-4f21-82e8-10f8fb8cfd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(imdb_csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8ac50f7-1ff6-4674-99ca-581914f9a098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ea0d379-4dfb-47e7-ba5d-fcee48692442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 13:34:06.357117: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    corpus_generator=df.review,\n",
    "    target_vocab_size=2**13,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddbcb6c0-f9e4-4859-ac1c-3e57288ee0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8011"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.subwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0628a771-eaed-4b49-93eb-863596468a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the_',\n",
       " ', ',\n",
       " '. ',\n",
       " 'a_',\n",
       " 'and_',\n",
       " 'of_',\n",
       " 'to_',\n",
       " 's_',\n",
       " 'is_',\n",
       " 'br',\n",
       " 'in_',\n",
       " 'I_',\n",
       " 'that_',\n",
       " 'this_',\n",
       " 'it_',\n",
       " ' /><',\n",
       " ' />',\n",
       " 'was_',\n",
       " 'The_',\n",
       " 't_',\n",
       " 'as_',\n",
       " 'with_',\n",
       " 'for_',\n",
       " '.<',\n",
       " 'on_',\n",
       " 'but_',\n",
       " 'movie_',\n",
       " 'are_',\n",
       " ' (',\n",
       " 'have_',\n",
       " 'his_',\n",
       " 'film_',\n",
       " 'not_',\n",
       " 'be_',\n",
       " 'you_',\n",
       " 'ing_',\n",
       " ' \"',\n",
       " 'ed_',\n",
       " 'it',\n",
       " 'd_',\n",
       " 'an_',\n",
       " 'at_',\n",
       " 'by_',\n",
       " 'he_',\n",
       " 'one_',\n",
       " 'who_',\n",
       " 'from_',\n",
       " 'y_',\n",
       " 'or_',\n",
       " 'e_',\n",
       " 'like_',\n",
       " 'all_',\n",
       " '\" ',\n",
       " 'they_',\n",
       " 'so_',\n",
       " 'just_',\n",
       " 'has_',\n",
       " ') ',\n",
       " 'about_',\n",
       " 'her_',\n",
       " 'out_',\n",
       " 'This_',\n",
       " 'some_',\n",
       " 'movie',\n",
       " 'ly_',\n",
       " 'film',\n",
       " 'very_',\n",
       " 'more_',\n",
       " 'It_',\n",
       " 'what_',\n",
       " 'would_',\n",
       " 'when_',\n",
       " 'if_',\n",
       " 'good_',\n",
       " 'up_',\n",
       " 'which_',\n",
       " 'their_',\n",
       " 'only_',\n",
       " 'even_',\n",
       " 'my_',\n",
       " 'really_',\n",
       " 'had_',\n",
       " 'can_',\n",
       " 'no_',\n",
       " 'were_',\n",
       " 'see_',\n",
       " '? ',\n",
       " 'she_',\n",
       " 'than_',\n",
       " '! ',\n",
       " 'there_',\n",
       " 'been_',\n",
       " 'get_',\n",
       " 'into_',\n",
       " 'will_',\n",
       " ' - ',\n",
       " 'much_',\n",
       " 'n_',\n",
       " 'because_',\n",
       " 'ing']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.subwords[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c86e1c7-68d2-4bcc-b1d7-2d84f3b854a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's mind-blowing to me that this film was even made.\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"It's mind-blowing to me that this film was even made.\"\n",
    "print(sample_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1450a175-ce25-43a5-a3eb-264dcda36037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 79, 681, 8058]\n"
     ]
    }
   ],
   "source": [
    "# returns encoded integer sequence\n",
    "\n",
    "tokenized = tokenizer.encode(sample_sentence)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ffc2a82c-00cc-4179-9db1-003498a7e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's mind-blowing to me that this film was even made.\n"
     ]
    }
   ],
   "source": [
    "# returns decoded original sentence\n",
    "\n",
    "original_sentence = tokenizer.decode(tokenized)\n",
    "print(original_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ec7da6f-2912-4696-be33-90a0a8046a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8268"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "438f101c-3a32-476e-a219-23a5138957a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 -> It\n",
      "8051 -> '\n",
      "8 -> s \n",
      "910 -> mind\n",
      "8057 -> -\n",
      "2169 -> blow\n",
      "36 -> ing \n",
      "7 -> to \n",
      "103 -> me \n",
      "13 -> that \n",
      "14 -> this \n",
      "32 -> film \n",
      "18 -> was \n",
      "79 -> even \n",
      "681 -> made\n",
      "8058 -> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized:\n",
    "    print(f\"{ts} -> {tokenizer.decode([ts])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f300d25-e672-4d1c-8d7d-67f593b8f816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's mind-blowing to me that this film was evenxyz made.\n"
     ]
    }
   ],
   "source": [
    "# add \"xyz\" right after \"even\"\n",
    "\n",
    "sample_sentence = \"It's mind-blowing to me that this film was evenxyz made.\"\n",
    "print(sample_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "262af4d9-5194-473c-ab72-60da255d8aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 7974, 8132, 8133, 997, 681, 8058]\n"
     ]
    }
   ],
   "source": [
    "# returns encoded integer sequence\n",
    "\n",
    "tokenized = tokenizer.encode(sample_sentence)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c72a087d-ac49-4b08-84a3-83b059dd284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's mind-blowing to me that this film was evenxyz made.\n"
     ]
    }
   ],
   "source": [
    "# returns decoded original sentence\n",
    "\n",
    "original_sentence = tokenizer.decode(tokenized)\n",
    "print(original_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b198308c-4b6e-4ed1-a00a-be8c6040ba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 -> It\n",
      "8051 -> '\n",
      "8 -> s \n",
      "910 -> mind\n",
      "8057 -> -\n",
      "2169 -> blow\n",
      "36 -> ing \n",
      "7 -> to \n",
      "103 -> me \n",
      "13 -> that \n",
      "14 -> this \n",
      "32 -> film \n",
      "18 -> was \n",
      "7974 -> even\n",
      "8132 -> x\n",
      "8133 -> y\n",
      "997 -> z \n",
      "681 -> made\n",
      "8058 -> .\n"
     ]
    }
   ],
   "source": [
    "# since \"xyz\" does not appeared in the train data, it is spliited into \"x\", \"y\", \"z\" separately\n",
    "\n",
    "for ts in tokenized:\n",
    "    print(f\"{ts} -> {tokenizer.decode([ts])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d9965-9cfc-4a4b-ae9f-37f90db357fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f8d954-4e58-4942-bf83-c7adc51734be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665353f-578a-4330-90db-63efb8ae325c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bb8dd1e-4bec-428d-8c82-0738e5a71970",
   "metadata": {},
   "source": [
    "## 4. Huggingface Tokenizer\n",
    "BERT uses WordPiece Tokenizer, which is implemented as `BertWordPieceTokenizer` in Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e8ab324-477b-40aa-93cf-6c43bbf943fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "import pandas as pd\n",
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b18ba2c-fbc1-4a6f-ada8-17c1acfd2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already downloaded imdb dataset in Section 2.\n",
    "data_dir = \"../data/\"\n",
    "\n",
    "csv_path = os.path.join(data_dir, \"naver_movie_review.csv\")\n",
    "txt_path = os.path.join(data_dir, \"naver_movie_review.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1cc37218-72e2-4078-bbd4-cc3f25497cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6f7d921-0138-4cfd-b212-1419c2f933ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "002a27e0-878c-4b81-86de-46571b1b25ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9e76e50-93df-412a-b8c6-dad9d12f6399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48fbd8db-16f3-474d-8a54-9e13e8b23bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199992, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e3780e20-edb3-4cde-9881-e744bd57c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- lowercase: ignore case sensitive if True\n",
    "- strip_accents: remove accent if True (e.g. é → e, ô → o)\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = BertWordPieceTokenizer(lowercase=False, strip_accents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10c6da8d-5057-4f9d-9184-c130266df3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- files: list of paths of train data\n",
    "- vocab_size: vocabulary size\n",
    "- limit_alphabet: the number of tokens allowed before merge\n",
    "- min_frequency: merge pair only if it appears more than this number\n",
    "\"\"\"\n",
    "\n",
    "tokenizer.train(\n",
    "    files=txt_path,\n",
    "    vocab_size=30000,\n",
    "    limit_alphabet=6000,\n",
    "    min_frequency=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df671d4d-16cd-43e9-880e-971d1669212f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/bert_naver_moview_tokenizer/vocab.txt']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_dir = \"../model/\"\n",
    "os.makedirs(base_model_dir, exist_ok=True)\n",
    "\n",
    "model_dir = os.path.join(base_model_dir, \"bert_naver_moview_tokenizer\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "tokenizer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b926fb9-6ab4-4575-b301-5abf935cb9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vocab = pd.read_fwf(os.path.join(model_dir, \"vocab.txt\"), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb0a2208-7d93-4cf7-b7e5-dab290c36459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[UNK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[MASK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0    [PAD]\n",
       "1    [UNK]\n",
       "2    [CLS]\n",
       "3    [SEP]\n",
       "4   [MASK]\n",
       "5        !\n",
       "6        \"\n",
       "7        #\n",
       "8        $\n",
       "9        %\n",
       "10       &\n",
       "11       '\n",
       "12       (\n",
       "13       )\n",
       "14       *\n",
       "15       +\n",
       "16       ,\n",
       "17       -\n",
       "18       .\n",
       "19       /\n",
       "20       0\n",
       "21       1\n",
       "22       2\n",
       "23       3\n",
       "24       4\n",
       "25       5\n",
       "26       6\n",
       "27       7\n",
       "28       8\n",
       "29       9"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vocab.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c2de8a5-b27b-48c9-98d2-309083c6f534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: vocab size was 30,000\n",
    "\n",
    "df_vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31afe706-f425-40de-9df8-f82d97027848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['아', '배고', '##픈', '##데', '짜장면', '##먹고', '##싶다']\n",
      "Token Ids: [2111, 20632, 4184, 3283, 24680, 7873, 7379]\n",
      "Decoded: 아 배고픈데 짜장면먹고싶다\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"아 배고픈데 짜장면먹고싶다\"\n",
    "encoded = tokenizer.encode(sample_sentence)\n",
    "\n",
    "print(f\"Tokens: {encoded.tokens}\")\n",
    "print(f\"Token Ids: {encoded.ids}\")\n",
    "print(f\"Decoded: {tokenizer.decode(encoded.ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd210c1c-1925-42b1-8600-3d6c29bae761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['커피', '한잔', '##의', '여유', '##를', '즐기', '##자']\n",
      "Token Ids: [12825, 25647, 3270, 12696, 3247, 10784, 3648]\n",
      "Decoded: 커피 한잔의 여유를 즐기자\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"커피 한잔의 여유를 즐기자\"\n",
    "encoded = tokenizer.encode(sample_sentence)\n",
    "\n",
    "print(f\"Tokens: {encoded.tokens}\")\n",
    "print(f\"Token Ids: {encoded.ids}\")\n",
    "print(f\"Decoded: {tokenizer.decode(encoded.ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122ce34-f56c-46d7-9c8c-ada3f6da0ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4e80f-9386-45b6-bddd-6fc648f8f2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36276fc6-a557-4f9d-8ea7-bc4e2cd5a9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15284b-e52d-4d7a-b0e3-eb11c851a01e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
