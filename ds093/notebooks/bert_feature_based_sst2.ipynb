{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95293003-f6d3-4e87-8f07-fe4a3c042ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b73578d-8656-4a77-9671-ea1e3e035617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 11:43:39.076918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from src.datasets.sst2 import load_sst2\n",
    "from src.utils.logger import get_logger\n",
    "from src.utils.session import reset_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2eaead-1365-4333-9696-5a3c4adf6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9947780-8701-4da9-9151-ca084ae173af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a194252-2b57-4c0f-a32a-d4abf70b141e",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "- `datasets.sst2.load_sst2`\n",
    "    - use `bert-base-uncased`\n",
    "- `datasets.kmreview.load_korean_moview_review`\n",
    "    - use `bert-base-multilingual-uncased`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e38ce2db-97e5-4ac0-aa64-f799e4211b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] num train: 3200 (data.py:33)\n",
      "[INFO] num valid: 800 (data.py:34)\n",
      "[INFO] num test: 1000 (data.py:35)\n"
     ]
    }
   ],
   "source": [
    "(X_train_raw, y_train_raw), (X_valid_raw, y_valid_raw), (X_test_raw, y_test_raw) = load_sst2(\n",
    "    num_sample=5000,\n",
    "    val_split=True,\n",
    ")\n",
    "\n",
    "X_raw = {\n",
    "    \"X_train\": X_train_raw,\n",
    "    \"X_valid\": X_valid_raw,\n",
    "    \"X_test\": X_test_raw,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1694b46-66ab-44e7-98c7-1dfc8b847689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "595eddd2-e475-4941-a7d7-ff011079d697",
   "metadata": {},
   "source": [
    "## Preproess\n",
    "<!-- - we will use last hidden states to  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e58d8-02b4-418e-9530-093fee536249",
   "metadata": {},
   "source": [
    "### Tokenize input sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c53345e8-774f-4a82-bc1e-b1b357f1e811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28aaddc9-3be0-47d6-a154-e74754d525ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Args:\n",
    " - return_tensors: returns numpy arra\n",
    " - max_length: limit the maximum length of sentence as 30\n",
    " - padding: fill with zeros if len(sentence) < max_length\n",
    " - truncation: truncate if len(sentence) > max_length\n",
    "\n",
    "Outputs:\n",
    " - input_ids: tokenized input ids\n",
    " - token_type_ids: 0 if first sentence, 1 if second sentence (note: BERT takes 2 sentences as input)\n",
    " - attention_mask: 0 if input_ids[i] = [PAD], 1 otherwise\n",
    "\"\"\"\n",
    "\n",
    "X_tokenized = {\n",
    "    k: tokenizer(v.tolist(), return_tensors=\"np\", max_length=30, padding=\"max_length\", truncation=True)\n",
    "    for k, v in X_raw.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04b05e4-897a-4693-b229-d76e2cfcfc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>\n",
      "Raw: a meditation on faith and madness , frailty is blood curdling stuff\n",
      "Token ids: [  101  1037 13804  2006  4752  1998 12013  1010 25737  3723  2003  2668\n",
      " 12731  4103  2989  4933   102     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "Ids to token: [CLS] a meditation on faith and madness , frail ##ty is blood cu ##rd ##ling stuff [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Attention Mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "==>\n",
      "Raw: has all the hallmarks of a movie designed strictly for children 's home video , a market so insatiable it absorbs all manner of lame entertainment , as long as 3 year olds find it diverting\n",
      "Token ids: [  101  2038  2035  1996 25812  2015  1997  1037  3185  2881  9975  2005\n",
      "  2336  1005  1055  2188  2678  1010  1037  3006  2061 16021 10450  3085\n",
      "  2009 16888  2015  2035  5450   102]\n",
      "Ids to token: [CLS] has all the hallmark ##s of a movie designed strictly for children ' s home video , a market so ins ##ati ##able it absorb ##s all manner [SEP]\n",
      "Attention Mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "==>\n",
      "Raw: without lrb de niro rrb , city by the sea would slip under the waves\n",
      "Token ids: [  101  2302  1048 15185  2139  9152  3217 25269  2497  1010  2103  2011\n",
      "  1996  2712  2052  7540  2104  1996  5975   102     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "Ids to token: [CLS] without l ##rb de ni ##ro rr ##b , city by the sea would slip under the waves [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Attention Mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "==>\n",
      "Raw: this version does justice both to stevenson and to the sci fi genre\n",
      "Token ids: [  101  2023  2544  2515  3425  2119  2000 13636  1998  2000  1996 16596\n",
      " 10882  6907   102     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "Ids to token: [CLS] this version does justice both to stevenson and to the sci fi genre [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Attention Mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 10, 13, 20]:\n",
    "    tmp_raw = X_raw[\"X_train\"][i]\n",
    "    tmp_tokenized = X_tokenized[\"X_train\"]\n",
    "    tmp_ids = tmp_tokenized[\"input_ids\"][i]\n",
    "    tmp_token_type_ids = tmp_tokenized[\"token_type_ids\"][i]\n",
    "    tmp_att_msk = tmp_tokenized[\"attention_mask\"][i]\n",
    "\n",
    "    print(\"==>\")\n",
    "    print(f\"Raw: {tmp_raw}\")\n",
    "    print(f\"Token ids: {tmp_ids}\")\n",
    "    print(f\"Ids to token: {' '.join(tokenizer.convert_ids_to_tokens(tmp_ids))}\")\n",
    "    print(f\"Attention Mask: {tmp_att_msk}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a2126-8dac-45c2-8956-13a48f483dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe46e068-c39c-4df3-a54b-1e9b0a914cc3",
   "metadata": {},
   "source": [
    "### Retrieve Last Hidden States / Pooler Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1d94139-eca4-4abc-a980-df1adb6f496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28faeb47-7651-4f24-93fd-205c265e79b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 11:43:44.330470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 11:43:44.332194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 11:43:44.332299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 11:43:44.332564: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-21 11:43:44.332847: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 11:43:44.332961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 11:43:44.333051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 11:43:44.685660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 11:43:44.685810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 11:43:44.685909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-21 11:43:44.685994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6660 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a408a4c5-cc5e-4454-8913-c0b781aeee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b697ba1b-8a27-4e11-970c-c92e0b29c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Outputs:\n",
    "  - last_hidden_state: hidden states of the last encoder block\n",
    "    - shape = (batch_size, max_length, 768)\n",
    "  - pooler_output: fc(last_hidden_state)\n",
    "    - shape = (batch_size, 768)\n",
    "  - hidden_states: hidden states of all encoder blocks\n",
    "    - length = 13 (note: bert uses 13 encoder blocks)\n",
    "    - shape of each hidden states = (batch_size, max_length, 768)\n",
    "\"\"\"\n",
    "\n",
    "X_features = {}\n",
    "for data_type, inputs in X_tokenized.items():\n",
    "    num_samples = inputs[\"input_ids\"].shape[0]\n",
    "    num_iter = num_samples // batch_size + 1\n",
    "    outputs = {\"last_hidden_state\": None, \"pooler_output\": None}\n",
    "    for i in range(num_iter):\n",
    "        s, e = i*batch_size, (i+1)*batch_size\n",
    "        cur_inputs = {k: v[s:e] for k, v in inputs.items()}\n",
    "\n",
    "        # batch inference\n",
    "        cur_outputs = model(cur_inputs)\n",
    "\n",
    "        # concat outputs\n",
    "        for k, v in outputs.items():\n",
    "            if v is None:                \n",
    "                outputs[k] = cur_outputs[k]\n",
    "            else:\n",
    "                outputs[k] = tf.concat([v, cur_outputs[k]], axis=0)\n",
    "    \n",
    "    X_features[data_type] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f00831-49af-489b-9734-5a19ea42c3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa724032-9112-45ce-aa56-794e67ec77a8",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e788f3c9-be27-4d4d-987d-3a5123d56a81",
   "metadata": {},
   "source": [
    "### Use Last Hidden States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a7c3cc1-7d92-48c0-a74c-c2f5c00dabdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (3200, 768)\n",
      "y_train: (3200,)\n",
      "X_test: (1000, 768)\n",
      "y_test: (1000,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTE:\n",
    "  - last_hidden_state.shape = (batch_size, tokens, 768)\n",
    "  - first token is [CLS], which contains overall information about the input sentence\n",
    "  - therefore, we only use the first token (=[CLS]) as the input features\n",
    "\"\"\"\n",
    "\n",
    "X_train = X_features[\"X_train\"][\"last_hidden_state\"][:, 0, :]\n",
    "y_train = y_train_raw\n",
    "\n",
    "X_test = X_features[\"X_test\"][\"last_hidden_state\"][:, 0, :]\n",
    "y_test = y_test_raw\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7745e11-b665-4715-acf4-58d85f3477d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, solver='saga')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000, solver=\"saga\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7310fcd-9f0e-4438-addb-63c34ab46f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "463f3d47-9c18-4591-9220-f5606a0fd496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1544\n",
      "           1       0.93      0.92      0.92      1656\n",
      "\n",
      "    accuracy                           0.92      3200\n",
      "   macro avg       0.92      0.92      0.92      3200\n",
      "weighted avg       0.92      0.92      0.92      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "841525d5-278b-4add-93fb-8a45cf68f84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       469\n",
      "           1       0.84      0.82      0.83       531\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.82      0.82      0.82      1000\n",
      "weighted avg       0.82      0.82      0.82      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468e9b5-5ef6-44fa-bc26-25098c030d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f8d2875-c9aa-40ab-8667-c4bacb6c66d6",
   "metadata": {},
   "source": [
    "### Use Pooler Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce9e88f0-9719-4308-8464-15687a9d841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (3200, 768)\n",
      "y_train: (3200,)\n",
      "X_test: (1000, 768)\n",
      "y_test: (1000,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTE:\n",
    "  - last_hidden_state.shape = (batch_size, tokens, 768)\n",
    "  - first token is [CLS], which contains overall information about the input sentence\n",
    "  - therefore, we only use the first token (=[CLS]) as the input features\n",
    "\"\"\"\n",
    "\n",
    "X_train = X_features[\"X_train\"][\"pooler_output\"]\n",
    "y_train = y_train_raw\n",
    "\n",
    "X_test = X_features[\"X_test\"][\"pooler_output\"]\n",
    "y_test = y_test_raw\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a753e62b-3b8b-43c3-abd2-9d85411163fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, solver='saga')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000, solver=\"saga\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3cf0ba3-8737-4462-a4f7-c1c675501b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "815f17bd-2a3d-47e0-ac69-793458c8691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      1544\n",
      "           1       0.89      0.86      0.87      1656\n",
      "\n",
      "    accuracy                           0.87      3200\n",
      "   macro avg       0.87      0.87      0.87      3200\n",
      "weighted avg       0.87      0.87      0.87      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12a07ed5-d4f8-4c29-a279-625234d8a995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       469\n",
      "           1       0.86      0.82      0.84       531\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.84      0.84      0.84      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951aeb22-f69d-4456-a706-9b1ab818a06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c400daf-5f32-4b70-bc17-c2b8125abf90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9cc15-6302-41e7-aa06-d520ebd11a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9103ae63-0c17-46a7-ae1b-7fe638a8f5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e90ee4-e90b-44e2-bcbc-bcc470b68b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
