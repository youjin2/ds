# DS053
## Introduction
A collection of examples in Data Science Series 053. (XAI; eXplainable AI)


## Datasets
- [Pima Indians Diabetes Database]
- [Loan Data]
- [The Japanese Female Facial Expression (JAFFE) Dataset]
- [Boston Housing Dataset]


## Papers
- [Slave to the Algorithm? Why a 'Right to an Explanation' Is Probably Not the Remedy You Are Looking For]
- [Visualizing and Understanding Convolutional Networks]
- [Layer-wise Relevance Propagation for Neural Networks with Local Renormalization Layers] (LRP)
- [Explaining NonLinear Classification Decisions with Deep Taylor Decomposition] (LRP)
- ["Why Should I Trust You?": Explaining the Predictions of Any Classifier] (LIME)
- [RANDOM FORESTS]
- [Model Class Reliance: Variable Importance Measures for any Machine Learning Model Class, from the "Rashomon" Perspective]
- [All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously]
- [Greedy function approximation: A gradient boosting machine] (PDP)
- [XGBoost: A Scalable Tree Boosting System]
- [Consistent Individualized Feature Attribution for Tree Ensembles] (SHAP)


## References
- [XAI; eXplainable AI]
- [Interpretable Machine Learning]



[Pima Indians Diabetes Database]: https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database
[Loan Data]: https://github.com/JaehyunAhn/XAI_dataset/blob/master/Ch1.loan/loanData.csv
[The Japanese Female Facial Expression (JAFFE) Dataset]: https://zenodo.org/records/3451524
[Boston Housing Dataset]: https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset


[Slave to the Algorithm? Why a 'Right to an Explanation' Is Probably Not the Remedy You Are Looking For]: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2972855
[Visualizing and Understanding Convolutional Networks]: https://arxiv.org/abs/1311.2901
[Layer-wise Relevance Propagation for Neural Networks with Local Renormalization Layers]: https://arxiv.org/abs/1604.00825
[Explaining NonLinear Classification Decisions with Deep Taylor Decomposition]: https://arxiv.org/abs/1512.02479
["Why Should I Trust You?": Explaining the Predictions of Any Classifier]: https://arxiv.org/abs/1602.04938
[RANDOM FORESTS]: https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf
[Model Class Reliance: Variable Importance Measures for any Machine Learning Model Class, from the "Rashomon" Perspective]: https://www.semanticscholar.org/paper/Model-Class-Reliance%3A-Variable-Importance-Measures-Fisher-Rudin/45a3c22cb3c63cbb3a89732b962c09305bd8b37e
[All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously]: https://arxiv.org/abs/1801.01489
[Greedy function approximation: A gradient boosting machine]: https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boosting-machine/10.1214/aos/1013203451.full
[XGBoost: A Scalable Tree Boosting System]: https://arxiv.org/abs/1603.02754
[Consistent Individualized Feature Attribution for Tree Ensembles]: https://arxiv.org/abs/1802.03888

[XAI; eXplainable AI]: https://github.com/wikibook/xai
[Interpretable Machine Learning]: https://christophm.github.io/interpretable-ml-book/
